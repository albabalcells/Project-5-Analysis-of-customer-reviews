{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following steps from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended</th>\n",
       "      <th>pos_feedback_count</th>\n",
       "      <th>division</th>\n",
       "      <th>department</th>\n",
       "      <th>class</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>review_char</th>\n",
       "      <th>review_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.339583</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>303</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>0.356294</td>\n",
       "      <td>500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>0.512891</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>192</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  age                                        review_text  \\\n",
       "0          767   33  Absolutely wonderful - silky and sexy and comf...   \n",
       "1         1080   34  Love this dress!  it's sooo pretty.  i happene...   \n",
       "2         1077   60  I had such high hopes for this dress and reall...   \n",
       "3         1049   50  I love, love, love this jumpsuit. it's fun, fl...   \n",
       "4          847   47  This shirt is very flattering to all due to th...   \n",
       "\n",
       "   rating  recommended  pos_feedback_count        division department  \\\n",
       "0       4            1                   0       Initmates   Intimate   \n",
       "1       5            1                   4         General    Dresses   \n",
       "2       3            0                   0         General    Dresses   \n",
       "3       5            1                   0  General Petite    Bottoms   \n",
       "4       5            1                   6         General       Tops   \n",
       "\n",
       "       class  polarity  subjectivity  review_char  review_words  sentiment  \n",
       "0  Intimates  0.633333      0.933333           53             8          1  \n",
       "1    Dresses  0.339583      0.725000          303            62          1  \n",
       "2    Dresses  0.073675      0.356294          500            98          1  \n",
       "3      Pants  0.550000      0.625000          124            22          1  \n",
       "4    Blouses  0.512891      0.568750          192            36          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('./data/Womens Clothing E-Commerce Reviews_clean.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(df['review_text']))\n",
    "\n",
    "print(data_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'wonderful', 'silky', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
    "\n",
    "For example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n",
    "\n",
    "This is used as the input by the LDA model.\n",
    "\n",
    "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absolutely'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('absolutely', 1), ('comfortable', 1), ('silky', 1), ('wonderful', 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.062*\"dress\" + 0.049*\"wear\" + 0.046*\"love\" + 0.034*\"color\" + 0.030*\"great\" '\n",
      "  '+ 0.021*\"buy\" + 0.020*\"well\" + 0.019*\"get\" + 0.018*\"flattering\" + '\n",
      "  '0.017*\"perfect\"'),\n",
      " (1,\n",
      "  '0.072*\"size\" + 0.058*\"fit\" + 0.040*\"small\" + 0.032*\"order\" + 0.027*\"go\" + '\n",
      "  '0.026*\"little\" + 0.025*\"try\" + 0.024*\"large\" + 0.022*\"run\" + 0.022*\"long\"'),\n",
      " (2,\n",
      "  '0.054*\"look\" + 0.044*\"top\" + 0.031*\"would\" + 0.028*\"fabric\" + 0.023*\"make\" '\n",
      "  '+ 0.018*\"much\" + 0.015*\"nice\" + 0.015*\"good\" + 0.015*\"also\" + 0.015*\"back\"'),\n",
      " (3,\n",
      "  '0.098*\"pant\" + 0.071*\"pair\" + 0.036*\"thick\" + 0.029*\"end\" + 0.028*\"lace\" + '\n",
      "  '0.021*\"heel\" + 0.020*\"cotton\" + 0.016*\"wardrobe\" + 0.014*\"walk\" + '\n",
      "  '0.014*\"version\"'),\n",
      " (4,\n",
      "  '0.039*\"blouse\" + 0.037*\"low\" + 0.031*\"slip\" + 0.025*\"thought\" + '\n",
      "  '0.022*\"belt\" + 0.022*\"elastic\" + 0.018*\"today\" + 0.017*\"available\" + '\n",
      "  '0.016*\"curve\" + 0.015*\"cardigan\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.579938113436239\n",
      "\n",
      "Coherence Score:  0.32297281038610515\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el949853215640485638359094\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el949853215640485638359094_data = {\"mdsDat\": {\"x\": [0.21188469747956729, 0.18849594807119757, 0.12677042750691628, -0.2642608660297221, -0.26289020702795896], \"y\": [-0.25909617976925486, -0.05606622659355548, 0.380523607304202, -0.03269389650038864, -0.032667304441002576], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [36.78334426879883, 30.59967803955078, 25.49655532836914, 3.6382060050964355, 3.4822278022766113]}, \"tinfo\": {\"Term\": [\"size\", \"dress\", \"fit\", \"look\", \"wear\", \"love\", \"top\", \"small\", \"color\", \"pant\", \"order\", \"great\", \"fabric\", \"would\", \"try\", \"little\", \"go\", \"large\", \"pair\", \"make\", \"run\", \"buy\", \"long\", \"length\", \"well\", \"short\", \"flattering\", \"get\", \"much\", \"perfect\", \"dress\", \"wear\", \"love\", \"color\", \"great\", \"perfect\", \"soft\", \"buy\", \"flattering\", \"comfortable\", \"work\", \"beautiful\", \"skirt\", \"purchase\", \"black\", \"style\", \"fall\", \"summer\", \"time\", \"jean\", \"person\", \"print\", \"piece\", \"gorgeous\", \"many\", \"light\", \"day\", \"casual\", \"compliment\", \"blue\", \"get\", \"super\", \"shirt\", \"see\", \"well\", \"design\", \"feel\", \"cute\", \"material\", \"quality\", \"really\", \"pretty\", \"much\", \"also\", \"good\", \"back\", \"sleeve\", \"way\", \"sweater\", \"cut\", \"return\", \"picture\", \"price\", \"bottom\", \"shoulder\", \"model\", \"however\", \"side\", \"front\", \"give\", \"detail\", \"keep\", \"loose\", \"thin\", \"seem\", \"shape\", \"bust\", \"body\", \"show\", \"weight\", \"hip\", \"overall\", \"look\", \"top\", \"waist\", \"make\", \"fabric\", \"would\", \"nice\", \"even\", \"still\", \"think\", \"bit\", \"enough\", \"size\", \"small\", \"order\", \"try\", \"large\", \"run\", \"length\", \"short\", \"petite\", \"find\", \"big\", \"medium\", \"retailer\", \"store\", \"tight\", \"usually\", \"true\", \"perfectly\", \"may\", \"high\", \"lbs\", \"need\", \"regular\", \"arm\", \"normally\", \"usual\", \"hit\", \"stretch\", \"probably\", \"tall\", \"fit\", \"long\", \"sale\", \"little\", \"go\", \"could\", \"want\", \"blouse\", \"low\", \"slip\", \"thought\", \"belt\", \"elastic\", \"today\", \"available\", \"curve\", \"cardigan\", \"exchange\", \"wrong\", \"skinny\", \"yet\", \"sit\", \"tuck\", \"sometimes\", \"similar\", \"awkward\", \"elegant\", \"zip\", \"leave\", \"band\", \"office\", \"mail\", \"bodice\", \"sort\", \"sexy\", \"negative\", \"cup\", \"pant\", \"pair\", \"thick\", \"end\", \"lace\", \"heel\", \"cotton\", \"wardrobe\", \"walk\", \"version\", \"ever\", \"staple\", \"lose\", \"point\", \"addition\", \"combination\", \"subtle\", \"rich\", \"flower\", \"interesting\", \"lining\", \"gold\", \"scratchy\", \"fabulous\", \"orange\", \"expensive\", \"bring\", \"silky\", \"cuff\", \"hug\"], \"Freq\": [10099.0, 12711.0, 8265.0, 9231.0, 9887.0, 9329.0, 7574.0, 5692.0, 6952.0, 1881.0, 4505.0, 6050.0, 4847.0, 5443.0, 3588.0, 3732.0, 3980.0, 3414.0, 1365.0, 4006.0, 3173.0, 4217.0, 3116.0, 2934.0, 4121.0, 2655.0, 3605.0, 3843.0, 2985.0, 3535.0, 12711.1513671875, 9886.9990234375, 9328.4296875, 6951.5712890625, 6050.0341796875, 3535.1572265625, 3316.32861328125, 4216.46484375, 3604.65185546875, 3056.392333984375, 3035.5322265625, 2970.76318359375, 2535.608642578125, 2285.501220703125, 1814.86767578125, 1777.966796875, 1730.4283447265625, 1302.2720947265625, 1290.02587890625, 1275.7764892578125, 1270.069091796875, 1193.255615234375, 1184.61865234375, 1158.9342041015625, 1128.1265869140625, 1117.8016357421875, 1103.557373046875, 1092.7225341796875, 1008.867919921875, 983.369384765625, 3807.893310546875, 1551.7191162109375, 2309.22998046875, 2939.1689453125, 4061.175537109375, 1672.19970703125, 3197.615966796875, 2437.012939453125, 2594.331298828125, 1829.5140380859375, 2447.794189453125, 1366.4698486328125, 2984.646728515625, 2522.76318359375, 2568.8046875, 2489.66552734375, 2238.02490234375, 2173.803955078125, 2041.8306884765625, 2039.024658203125, 1853.9783935546875, 1733.7928466796875, 1665.58203125, 1592.3770751953125, 1516.4056396484375, 1501.05419921875, 1436.6302490234375, 1434.7830810546875, 1298.3839111328125, 1255.154052734375, 1201.707763671875, 1190.2332763671875, 1162.439208984375, 1117.167724609375, 1091.6849365234375, 990.534912109375, 985.5718994140625, 970.3168334960938, 981.137939453125, 941.113525390625, 840.5797119140625, 826.43994140625, 9221.71875, 7495.49462890625, 2443.86328125, 3950.224365234375, 4768.359375, 5199.2841796875, 2621.016845703125, 1951.7779541015625, 1712.431396484375, 2357.625244140625, 2094.46337890625, 1292.2066650390625, 10098.4853515625, 5691.25927734375, 4504.97265625, 3587.7314453125, 3413.497314453125, 3172.689453125, 2933.539306640625, 2654.30029296875, 2442.45751953125, 2245.018798828125, 2147.81640625, 2140.68212890625, 2070.29296875, 2025.5615234375, 1819.72705078125, 1793.826416015625, 1761.0595703125, 1607.2987060546875, 1472.9722900390625, 1331.5185546875, 1212.083984375, 1205.443603515625, 1071.305419921875, 1052.751953125, 892.792236328125, 889.5455932617188, 885.205810546875, 871.4606323242188, 826.913818359375, 798.91162109375, 8213.2177734375, 3106.37939453125, 1572.927490234375, 3658.724853515625, 3775.15966796875, 1617.9654541015625, 1855.880126953125, 776.6331176757812, 741.1448364257812, 625.6279296875, 511.3454895019531, 451.3764953613281, 449.2480163574219, 359.48052978515625, 346.653564453125, 332.0126647949219, 295.7860107421875, 295.52154541015625, 286.3676452636719, 254.453857421875, 251.1166229248047, 248.65838623046875, 249.54188537597656, 237.1044158935547, 236.64108276367188, 233.203369140625, 222.03514099121094, 215.08396911621094, 202.0301971435547, 178.4862060546875, 178.58261108398438, 161.07415771484375, 160.93145751953125, 142.7013702392578, 139.69937133789062, 139.45895385742188, 136.046630859375, 1881.0758056640625, 1364.605712890625, 689.4202270507812, 554.10791015625, 540.115478515625, 406.4220886230469, 378.2553405761719, 317.8306884765625, 265.4770812988281, 265.38885498046875, 255.5271759033203, 236.59652709960938, 237.115966796875, 223.82418823242188, 198.21951293945312, 198.3321075439453, 183.30738830566406, 181.3489227294922, 175.83346557617188, 174.44757080078125, 166.4269561767578, 161.6149139404297, 159.31602478027344, 150.40283203125, 129.2753143310547, 125.7983169555664, 126.40021514892578, 120.54046630859375, 117.17320251464844, 110.32209777832031], \"Total\": [10099.0, 12711.0, 8265.0, 9231.0, 9887.0, 9329.0, 7574.0, 5692.0, 6952.0, 1881.0, 4505.0, 6050.0, 4847.0, 5443.0, 3588.0, 3732.0, 3980.0, 3414.0, 1365.0, 4006.0, 3173.0, 4217.0, 3116.0, 2934.0, 4121.0, 2655.0, 3605.0, 3843.0, 2985.0, 3535.0, 12711.9560546875, 9887.8017578125, 9329.232421875, 6952.373046875, 6050.8359375, 3535.95849609375, 3317.1298828125, 4217.53173828125, 3605.5712890625, 3057.19287109375, 3036.335205078125, 2971.564453125, 2536.41259765625, 2286.302734375, 1815.6717529296875, 1778.7685546875, 1731.2288818359375, 1303.0718994140625, 1290.8284912109375, 1276.5780029296875, 1270.8701171875, 1194.0616455078125, 1185.4189453125, 1159.7359619140625, 1128.9278564453125, 1118.6051025390625, 1104.359130859375, 1093.52587890625, 1009.6658325195312, 984.16943359375, 3843.095947265625, 1553.5172119140625, 2324.043701171875, 2965.438720703125, 4121.11865234375, 1682.0406494140625, 3263.874755859375, 2711.342529296875, 2975.83642578125, 2114.2255859375, 3307.31982421875, 2225.6484375, 2985.446044921875, 2523.562255859375, 2569.62646484375, 2490.462646484375, 2238.826904296875, 2174.604736328125, 2042.6322021484375, 2039.8271484375, 1854.77734375, 1734.5916748046875, 1666.3843994140625, 1593.17919921875, 1517.20751953125, 1501.8526611328125, 1437.4273681640625, 1435.581298828125, 1299.18212890625, 1255.9525146484375, 1202.50390625, 1191.02880859375, 1163.2379150390625, 1117.968505859375, 1092.48291015625, 991.3309326171875, 986.3710327148438, 971.1127319335938, 981.9537963867188, 941.917236328125, 841.3764038085938, 827.240478515625, 9231.0615234375, 7574.13525390625, 2446.305908203125, 4006.3701171875, 4847.23828125, 5443.27978515625, 2919.14208984375, 2171.66357421875, 1861.2086181640625, 2922.399658203125, 2808.86962890625, 1373.43212890625, 10099.2890625, 5692.06298828125, 4505.775390625, 3588.536865234375, 3414.2998046875, 3173.491943359375, 2934.34375, 2655.103271484375, 2443.26123046875, 2245.82666015625, 2148.620361328125, 2141.48388671875, 2071.0966796875, 2026.3648681640625, 1820.5340576171875, 1794.62890625, 1761.864990234375, 1608.104248046875, 1473.7762451171875, 1332.325439453125, 1212.8865966796875, 1206.2474365234375, 1072.106689453125, 1053.5540771484375, 893.5955200195312, 890.3487548828125, 886.0103149414062, 872.2680053710938, 827.7211303710938, 799.7166137695312, 8265.1787109375, 3116.76904296875, 1576.0924072265625, 3732.1337890625, 3980.5927734375, 1650.591064453125, 1998.796875, 777.4317626953125, 741.9495239257812, 626.4392700195312, 512.1531982421875, 452.1835021972656, 450.0593566894531, 360.2843017578125, 347.46356201171875, 332.8205261230469, 296.5869445800781, 296.3263854980469, 287.1719055175781, 255.2626495361328, 251.9224395751953, 249.46250915527344, 250.3528594970703, 237.90855407714844, 237.44839477539062, 234.02098083496094, 222.84373474121094, 215.8914031982422, 202.82882690429688, 179.2872314453125, 179.39630126953125, 161.87576293945312, 161.7349090576172, 143.50601196289062, 140.501220703125, 140.26951599121094, 136.84547424316406, 1881.87744140625, 1365.4102783203125, 690.2269897460938, 554.9140014648438, 540.9229125976562, 407.2301025390625, 379.0628662109375, 318.6324462890625, 266.28717041015625, 266.2000732421875, 256.3332214355469, 237.39866638183594, 237.93331909179688, 224.63035583496094, 199.02105712890625, 199.1571502685547, 184.1143341064453, 182.15296936035156, 176.63766479492188, 175.2522430419922, 167.23484802246094, 162.42283630371094, 160.1243133544922, 151.21104431152344, 130.0768280029297, 126.60614776611328, 127.21273040771484, 121.35165405273438, 117.97787475585938, 111.13236999511719], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.7744998931884766, -3.025700092315674, -3.083899974822998, -3.378000020980835, -3.516900062561035, -4.054200172424316, -4.118100166320801, -3.8778998851776123, -4.0346999168396, -4.199699878692627, -4.206600189208984, -4.228099822998047, -4.386499881744385, -4.4903998374938965, -4.720900058746338, -4.741499900817871, -4.768599987030029, -5.052800178527832, -5.062300205230713, -5.073400020599365, -5.077899932861328, -5.1402997970581055, -5.147500038146973, -5.169400215148926, -5.196400165557861, -5.205599784851074, -5.218400001525879, -5.228300094604492, -5.30810022354126, -5.333700180053711, -3.9798998832702637, -4.877600193023682, -4.480000019073486, -4.238800048828125, -3.9154999256134033, -4.802800178527832, -4.1545000076293945, -4.426199913024902, -4.36359977722168, -4.712900161743164, -4.421800136566162, -5.004700183868408, -4.039400100708008, -4.207499980926514, -4.1894001960754395, -4.220699787139893, -4.327300071716309, -4.356400012969971, -4.419000148773193, -4.420400142669678, -4.515600204467773, -4.582600116729736, -4.622700214385986, -4.667699813842773, -4.7164998054504395, -4.7266998291015625, -4.770599842071533, -4.771900177001953, -4.871799945831299, -4.905600070953369, -4.949100017547607, -4.958700180053711, -4.982399940490723, -5.02209997177124, -5.045199871063232, -5.142399787902832, -5.14739990234375, -5.163000106811523, -5.151899814605713, -5.193600177764893, -5.30649995803833, -5.323500156402588, -2.91129994392395, -3.1185998916625977, -4.239299774169922, -3.7590999603271484, -3.5708999633789062, -3.4844000339508057, -4.169300079345703, -4.464099884033203, -4.59499979019165, -4.275199890136719, -4.393599987030029, -4.876500129699707, -2.6380999088287354, -3.2114999294281006, -3.4453001022338867, -3.6728999614715576, -3.7227001190185547, -3.7959001064300537, -3.8742001056671143, -3.974299907684326, -4.057400226593018, -4.14169979095459, -4.185999870300293, -4.189300060272217, -4.222700119018555, -4.24459981918335, -4.351799964904785, -4.366099834442139, -4.384500026702881, -4.475900173187256, -4.563199996948242, -4.664100170135498, -4.7581000328063965, -4.763599872589111, -4.8815999031066895, -4.89900016784668, -5.063799858093262, -5.067500114440918, -5.072400093078613, -5.0879998207092285, -5.140500068664551, -5.174900054931641, -2.8447000980377197, -3.816999912261963, -4.497499942779541, -3.6533000469207764, -3.621999979019165, -4.469299793243408, -4.332099914550781, -3.256200075149536, -3.3029000759124756, -3.472399950027466, -3.674099922180176, -3.798799991607666, -3.8036000728607178, -4.026500225067139, -4.06279993057251, -4.105999946594238, -4.221499919891357, -4.222400188446045, -4.253900051116943, -4.372000217437744, -4.385200023651123, -4.395100116729736, -4.391499996185303, -4.442599773406982, -4.4446001052856445, -4.459199905395508, -4.508299827575684, -4.54010009765625, -4.602700233459473, -4.726600170135498, -4.726099967956543, -4.8292999267578125, -4.8302001953125, -4.950399875640869, -4.97160005569458, -4.973400115966797, -4.9980998039245605, -2.327699899673462, -2.648699998855591, -3.3315000534057617, -3.549999952316284, -3.575500011444092, -3.8598999977111816, -3.93179988861084, -4.105800151824951, -4.285799980163574, -4.286099910736084, -4.323999881744385, -4.401000022888184, -4.398799896240234, -4.456500053405762, -4.577899932861328, -4.577400207519531, -4.656199932098389, -4.666900157928467, -4.697800159454346, -4.705699920654297, -4.752799987792969, -4.782100200653076, -4.79640007019043, -4.854000091552734, -5.00540018081665, -5.032599925994873, -5.027900218963623, -5.075300216674805, -5.103700160980225, -5.163899898529053], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.000100016593933, 1.0, 1.0, 1.0, 1.0, 0.9998999834060669, 0.9998999834060669, 0.9998999834060669, 0.9998999834060669, 0.9998999834060669, 0.9998999834060669, 0.9998999834060669, 0.9998000264167786, 0.9998000264167786, 0.9997000098228455, 0.9997000098228455, 0.9997000098228455, 0.9994999766349792, 0.9994999766349792, 0.9994999766349792, 0.9994999766349792, 0.9994000196456909, 0.9994000196456909, 0.9994000196456909, 0.9994000196456909, 0.9994000196456909, 0.9994000196456909, 0.9994000196456909, 0.9993000030517578, 0.9993000030517578, 0.9908999800682068, 0.9990000128746033, 0.9937000274658203, 0.9911999702453613, 0.9854999780654907, 0.9943000078201294, 0.9796000123023987, 0.8934999704360962, 0.8629000186920166, 0.8554999828338623, 0.6991999745368958, 0.5123000144958496, 1.183899998664856, 1.183899998664856, 1.183899998664856, 1.183899998664856, 1.1837999820709229, 1.1837999820709229, 1.1837999820709229, 1.1837999820709229, 1.1837999820709229, 1.1836999654769897, 1.1836999654769897, 1.1836999654769897, 1.1836999654769897, 1.1835999488830566, 1.1835999488830566, 1.1835999488830566, 1.1835999488830566, 1.183500051498413, 1.183500051498413, 1.183500051498413, 1.183500051498413, 1.183500051498413, 1.183500051498413, 1.18340003490448, 1.18340003490448, 1.18340003490448, 1.1833000183105469, 1.1833000183105469, 1.1832000017166138, 1.1832000017166138, 1.1832000017166138, 1.173699975013733, 1.1832000017166138, 1.1700999736785889, 1.167799949645996, 1.1382999420166016, 1.0765000581741333, 1.0773999691009521, 1.1009000539779663, 0.9693999886512756, 0.8906999826431274, 1.1232000589370728, 1.3665000200271606, 1.3665000200271606, 1.3664000034332275, 1.3664000034332275, 1.3664000034332275, 1.3664000034332275, 1.3664000034332275, 1.3662999868392944, 1.3662999868392944, 1.3662999868392944, 1.3662999868392944, 1.3662999868392944, 1.3661999702453613, 1.3661999702453613, 1.3661999702453613, 1.3661999702453613, 1.3661999702453613, 1.3660999536514282, 1.3660999536514282, 1.3660000562667847, 1.3660000562667847, 1.3660000562667847, 1.3659000396728516, 1.3659000396728516, 1.3657000064849854, 1.3657000064849854, 1.3657000064849854, 1.3657000064849854, 1.3657000064849854, 1.3655999898910522, 1.3602999448776245, 1.3632999658584595, 1.3645999431610107, 1.3467999696731567, 1.313599944114685, 1.3466999530792236, 1.2924000024795532, 3.312700033187866, 3.3125998973846436, 3.3124001026153564, 3.3120999336242676, 3.3118999004364014, 3.3118999004364014, 3.3113999366760254, 3.311300039291382, 3.311199903488159, 3.311000108718872, 3.311000108718872, 3.3108999729156494, 3.310499906539917, 3.310499906539917, 3.310499906539917, 3.3104000091552734, 3.31030011177063, 3.31030011177063, 3.3101999759674072, 3.309999942779541, 3.3099000453948975, 3.3097000122070312, 3.3092000484466553, 3.3090999126434326, 3.3087000846862793, 3.3087000846862793, 3.3080999851226807, 3.308000087738037, 3.3078999519348145, 3.307800054550171, 3.357100009918213, 3.3568999767303467, 3.356300115585327, 3.3559999465942383, 3.3559999465942383, 3.3554999828338623, 3.3554000854492188, 3.3550000190734863, 3.3545000553131104, 3.3543999195098877, 3.354300022125244, 3.354099988937378, 3.354099988937378, 3.3538999557495117, 3.3534998893737793, 3.353300094604492, 3.353100061416626, 3.353100061416626, 3.3529000282287598, 3.3529000282287598, 3.3526999950408936, 3.3524999618530273, 3.352400064468384, 3.352099895477295, 3.351300001144409, 3.351099967956543, 3.351099967956543, 3.350800037384033, 3.3506999015808105, 3.3501999378204346]}, \"token.table\": {\"Topic\": [5, 2, 3, 4, 4, 2, 4, 1, 4, 3, 1, 2, 3, 1, 4, 1, 4, 2, 2, 5, 2, 1, 4, 1, 1, 5, 1, 1, 5, 2, 3, 5, 4, 4, 2, 1, 2, 3, 1, 1, 2, 2, 1, 4, 4, 5, 1, 2, 3, 1, 2, 3, 5, 4, 5, 1, 2, 5, 1, 1, 2, 3, 1, 3, 1, 5, 2, 1, 3, 2, 1, 2, 3, 5, 2, 1, 1, 5, 3, 2, 3, 2, 5, 5, 1, 2, 5, 3, 3, 4, 3, 1, 5, 1, 2, 3, 2, 3, 1, 2, 2, 5, 1, 4, 4, 1, 2, 1, 1, 2, 3, 3, 2, 2, 3, 4, 1, 2, 3, 4, 5, 3, 2, 5, 5, 1, 3, 1, 3, 2, 1, 5, 1, 2, 2, 1, 3, 1, 1, 2, 1, 2, 3, 3, 2, 5, 3, 1, 3, 5, 1, 3, 2, 4, 2, 1, 2, 3, 2, 2, 2, 5, 4, 4, 3, 4, 1, 2, 4, 3, 1, 4, 4, 5, 1, 2, 3, 3, 3, 1, 5, 1, 1, 3, 2, 3, 5, 2, 1, 2, 3, 4, 3, 1, 4, 1, 2, 3, 3, 4, 3, 3, 5, 2, 3, 5, 1, 2, 3, 5, 2, 1, 2, 1, 2, 1, 2, 3, 4, 4, 4], \"Freq\": [0.994869589805603, 0.9997771978378296, 0.9994741082191467, 0.9986658692359924, 0.9956372380256653, 0.9998142123222351, 0.9928202629089355, 0.9998100399971008, 0.9973827004432678, 0.999711275100708, 0.13386167585849762, 0.745495617389679, 0.12033310532569885, 0.9996300339698792, 0.9994446039199829, 0.9988117814064026, 0.9954560995101929, 0.9988541603088379, 0.9992598295211792, 0.9904668927192688, 0.9996238350868225, 0.9996368288993835, 0.9980210065841675, 0.9995191097259521, 0.9999463558197021, 0.9941897392272949, 0.9996098279953003, 0.9993405342102051, 0.9971960783004761, 0.01938699372112751, 0.9802548885345459, 0.9917113780975342, 0.9938216805458069, 0.9975346326828003, 0.999594509601593, 0.898816704750061, 0.09478699415922165, 0.006269956473261118, 0.9996747970581055, 0.9940306544303894, 0.005350643768906593, 0.999580979347229, 0.9999247789382935, 0.9976462125778198, 0.9962137937545776, 0.9983528852462769, 0.01601826585829258, 0.9407090544700623, 0.04295807331800461, 0.07782052457332611, 0.8988500833511353, 0.023484300822019577, 0.9987000226974487, 0.9988985657691956, 0.9952123165130615, 0.016091637313365936, 0.9836528897285461, 0.9919910430908203, 0.9992901682853699, 0.9798170328140259, 0.020221363753080368, 0.999631941318512, 0.006170465610921383, 0.9936869144439697, 0.999841570854187, 0.9963899850845337, 0.9990900754928589, 0.9908677935600281, 0.009107240475714207, 0.9992415904998779, 0.05024377256631851, 0.0012560943141579628, 0.9483512043952942, 0.99739670753479, 0.9997562170028687, 0.9993653893470764, 0.9998618364334106, 0.9969793558120728, 0.9997557401657104, 0.9995526075363159, 0.998859703540802, 0.9997026920318604, 0.9898106455802917, 0.9928545951843262, 0.9995472431182861, 0.999136209487915, 0.9982938170433044, 0.9996193051338196, 0.9992690086364746, 0.9959136843681335, 0.9998828768730164, 0.9994590282440186, 0.9926160573959351, 0.011789502575993538, 0.007770353928208351, 0.9804043173789978, 0.0032084507402032614, 0.9965447783470154, 0.0009749691234901547, 0.9990183711051941, 0.9989358186721802, 0.9960774183273315, 0.9998679161071777, 0.9987202286720276, 0.9945899248123169, 0.013977739959955215, 0.9859299063682556, 0.9991781115531921, 0.8716877102851868, 0.12803122401237488, 0.9994732737541199, 0.9997740387916565, 0.9994322657585144, 0.9998505711555481, 0.998965859413147, 0.9909494519233704, 0.10208478569984436, 0.8978665471076965, 0.9993335604667664, 0.9977909326553345, 0.9917215704917908, 0.9998279213905334, 0.9985004663467407, 0.9996995329856873, 0.9995337128639221, 0.9997289180755615, 0.9993132948875427, 0.9993153214454651, 0.9994837641716003, 0.9996588826179504, 0.9996466040611267, 0.9971938133239746, 0.6137537360191345, 0.38595494627952576, 0.9997693300247192, 0.9991108775138855, 0.9991287589073181, 0.9998675584793091, 0.8655651807785034, 0.13432814180850983, 0.7401763796806335, 0.2597269117832184, 0.9989677667617798, 0.9994704723358154, 0.9995809197425842, 0.9936703443527222, 0.9998449683189392, 0.001903441734611988, 0.9980379343032837, 0.9929785132408142, 0.9910843968391418, 0.008767673745751381, 0.9995579719543457, 0.9964326024055481, 0.999666154384613, 0.9935269355773926, 0.006023983005434275, 0.9995844960212708, 0.9992040991783142, 0.9990286827087402, 0.9995951056480408, 0.9971022009849548, 0.9981116056442261, 0.9981459975242615, 0.9998723864555359, 0.9950535297393799, 0.999837338924408, 0.9996306300163269, 0.9992988109588623, 0.9998132586479187, 0.9996593594551086, 0.996181070804596, 0.9964739084243774, 0.9983206987380981, 0.019342269748449326, 0.9198324084281921, 0.060175951570272446, 0.9998199343681335, 0.998546302318573, 0.9995679259300232, 0.9939476251602173, 0.9991773962974548, 0.9990233778953552, 0.0006437006522901356, 0.9996904730796814, 0.9991039037704468, 0.9982223510742188, 0.9991337060928345, 0.0017109226901084185, 0.8068711757659912, 0.19128115475177765, 0.9977483153343201, 0.9997066259384155, 0.9993581771850586, 0.996435284614563, 0.01029820553958416, 0.9895519018173218, 0.9995090365409851, 0.9998503923416138, 0.9985905289649963, 0.9996082782745361, 0.9996495842933655, 0.9954918622970581, 0.999057412147522, 0.0008175592520274222, 0.9951662421226501, 0.027516553178429604, 0.04352618381381035, 0.9285585880279541, 0.9980151057243347, 0.999721884727478, 0.9999189376831055, 0.9990261793136597, 0.985412061214447, 0.014316501095890999, 0.999889612197876, 0.955122709274292, 0.04464220255613327, 0.9959191679954529, 0.996338427066803, 0.9958710670471191], \"Term\": [\"addition\", \"also\", \"arm\", \"available\", \"awkward\", \"back\", \"band\", \"beautiful\", \"belt\", \"big\", \"bit\", \"bit\", \"bit\", \"black\", \"blouse\", \"blue\", \"bodice\", \"body\", \"bottom\", \"bring\", \"bust\", \"buy\", \"cardigan\", \"casual\", \"color\", \"combination\", \"comfortable\", \"compliment\", \"cotton\", \"could\", \"could\", \"cuff\", \"cup\", \"curve\", \"cut\", \"cute\", \"cute\", \"cute\", \"day\", \"design\", \"design\", \"detail\", \"dress\", \"elastic\", \"elegant\", \"end\", \"enough\", \"enough\", \"enough\", \"even\", \"even\", \"even\", \"ever\", \"exchange\", \"expensive\", \"fabric\", \"fabric\", \"fabulous\", \"fall\", \"feel\", \"feel\", \"find\", \"fit\", \"fit\", \"flattering\", \"flower\", \"front\", \"get\", \"get\", \"give\", \"go\", \"go\", \"go\", \"gold\", \"good\", \"gorgeous\", \"great\", \"heel\", \"high\", \"hip\", \"hit\", \"however\", \"hug\", \"interesting\", \"jean\", \"keep\", \"lace\", \"large\", \"lbs\", \"leave\", \"length\", \"light\", \"lining\", \"little\", \"little\", \"little\", \"long\", \"long\", \"look\", \"look\", \"loose\", \"lose\", \"love\", \"low\", \"mail\", \"make\", \"make\", \"many\", \"material\", \"material\", \"may\", \"medium\", \"model\", \"much\", \"need\", \"negative\", \"nice\", \"nice\", \"normally\", \"office\", \"orange\", \"order\", \"overall\", \"pair\", \"pant\", \"perfect\", \"perfectly\", \"person\", \"petite\", \"picture\", \"piece\", \"point\", \"pretty\", \"pretty\", \"price\", \"print\", \"probably\", \"purchase\", \"quality\", \"quality\", \"really\", \"really\", \"regular\", \"retailer\", \"return\", \"rich\", \"run\", \"sale\", \"sale\", \"scratchy\", \"see\", \"see\", \"seem\", \"sexy\", \"shape\", \"shirt\", \"shirt\", \"short\", \"shoulder\", \"show\", \"side\", \"silky\", \"similar\", \"sit\", \"size\", \"skinny\", \"skirt\", \"sleeve\", \"slip\", \"small\", \"soft\", \"sometimes\", \"sort\", \"staple\", \"still\", \"still\", \"still\", \"store\", \"stretch\", \"style\", \"subtle\", \"summer\", \"super\", \"super\", \"sweater\", \"tall\", \"thick\", \"thin\", \"think\", \"think\", \"think\", \"thought\", \"tight\", \"time\", \"today\", \"top\", \"top\", \"true\", \"try\", \"tuck\", \"usual\", \"usually\", \"version\", \"waist\", \"waist\", \"walk\", \"want\", \"want\", \"want\", \"wardrobe\", \"way\", \"wear\", \"weight\", \"well\", \"well\", \"work\", \"would\", \"would\", \"wrong\", \"yet\", \"zip\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2, 5, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el949853215640485638359094\", ldavis_el949853215640485638359094_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el949853215640485638359094\", ldavis_el949853215640485638359094_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el949853215640485638359094\", ldavis_el949853215640485638359094_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.211885 -0.259096       1        1  36.783344\n",
       "2      0.188496 -0.056066       2        1  30.599678\n",
       "1      0.126770  0.380524       3        1  25.496555\n",
       "4     -0.264261 -0.032694       4        1   3.638206\n",
       "3     -0.262890 -0.032667       5        1   3.482228, topic_info=           Term          Freq         Total Category  logprob  loglift\n",
       "46         size  10099.000000  10099.000000  Default  30.0000  30.0000\n",
       "6         dress  12711.000000  12711.000000  Default  29.0000  29.0000\n",
       "30          fit   8265.000000   8265.000000  Default  28.0000  28.0000\n",
       "102        look   9231.000000   9231.000000  Default  27.0000  27.0000\n",
       "59         wear   9887.000000   9887.000000  Default  26.0000  26.0000\n",
       "...         ...           ...           ...      ...      ...      ...\n",
       "2036  expensive    125.798317    126.606148   Topic5  -5.0326   3.3511\n",
       "649       bring    126.400215    127.212730   Topic5  -5.0279   3.3511\n",
       "2         silky    120.540466    121.351654   Topic5  -5.0753   3.3508\n",
       "776        cuff    117.173203    117.977875   Topic5  -5.1037   3.3507\n",
       "905         hug    110.322098    111.132370   Topic5  -5.1639   3.3502\n",
       "\n",
       "[211 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "1174      5  0.994870   addition\n",
       "115       2  0.999777       also\n",
       "642       3  0.999474        arm\n",
       "1385      4  0.998666  available\n",
       "293       4  0.995637    awkward\n",
       "...     ...       ...        ...\n",
       "23        2  0.955123      would\n",
       "23        3  0.044642      would\n",
       "255       4  0.995919      wrong\n",
       "529       4  0.996338        yet\n",
       "54        4  0.995871        zip\n",
       "\n",
       "[221 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 2, 5, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LDA mallet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = './data/mallet-2.0.8/bin/mallet' \n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=5, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('color', 0.07948160742233681),\n",
      "   ('love', 0.048033508607974056),\n",
      "   ('soft', 0.03814756848659543),\n",
      "   ('nice', 0.031662031459358426),\n",
      "   ('sweater', 0.02124688953193789),\n",
      "   ('style', 0.02120185108035986),\n",
      "   ('fall', 0.020785245403263035),\n",
      "   ('sleeve', 0.01858962088883384),\n",
      "   ('feel', 0.017362323083332395),\n",
      "   ('beautiful', 0.016686746309661875)]),\n",
      " (1,\n",
      "  [('dress', 0.13161132987291926),\n",
      "   ('quality', 0.024196796133882228),\n",
      "   ('retailer', 0.023872382316090925),\n",
      "   ('store', 0.02286558081260068),\n",
      "   ('skirt', 0.022708967245391086),\n",
      "   ('make', 0.022619473778414174),\n",
      "   ('beautiful', 0.016511544657240022),\n",
      "   ('online', 0.015974583855378557),\n",
      "   ('feel', 0.015728476821192054),\n",
      "   ('sale', 0.01522507606944693)]),\n",
      " (2,\n",
      "  [('size', 0.10811638926277316),\n",
      "   ('fit', 0.09266493767987481),\n",
      "   ('small', 0.05898252410185702),\n",
      "   ('order', 0.05185866080124312),\n",
      "   ('large', 0.03732641738616592),\n",
      "   ('run', 0.03329941017475898),\n",
      "   ('short', 0.030694987032599062),\n",
      "   ('length', 0.029141087510806168),\n",
      "   ('long', 0.02822187934298502),\n",
      "   ('waist', 0.02473107689614042)]),\n",
      " (3,\n",
      "  [('wear', 0.11052560767781863),\n",
      "   ('great', 0.06721454838999014),\n",
      "   ('love', 0.05695578078751457),\n",
      "   ('buy', 0.044589200825186116),\n",
      "   ('perfect', 0.04165171764283792),\n",
      "   ('comfortable', 0.034083774329536284),\n",
      "   ('pant', 0.02301775944030855),\n",
      "   ('purchase', 0.02127993542021706),\n",
      "   ('super', 0.018297605166382635),\n",
      "   ('black', 0.0178267109157772)]),\n",
      " (4,\n",
      "  [('top', 0.08771113179944141),\n",
      "   ('back', 0.03036751341047125),\n",
      "   ('shirt', 0.02869397526266791),\n",
      "   ('fabric', 0.028405816376291172),\n",
      "   ('cut', 0.021290508489604114),\n",
      "   ('cute', 0.01624772797801126),\n",
      "   ('make', 0.01600390122800018),\n",
      "   ('bottom', 0.014962096023407367),\n",
      "   ('front', 0.01435252914837966),\n",
      "   ('side', 0.014274947909739771)])]\n",
      "\n",
      "Coherence Score:  0.4475101425204738\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v', topn=10)\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check coherence score amongs various topic numbers:\n",
    "    \n",
    "def lda_malle(number_topics):\n",
    "    coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v', topn=number_topics)\n",
    "    coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "    return coherence_ldamallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,21):\n",
    "#    print(f'{i} topics: coherence score {lda_malle(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    \n",
    "  \n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=10, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=10; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3486\n",
      "Num Topics = 3  has Coherence Value of 0.3944\n",
      "Num Topics = 4  has Coherence Value of 0.4044\n",
      "Num Topics = 5  has Coherence Value of 0.4113\n",
      "Num Topics = 6  has Coherence Value of 0.4361\n",
      "Num Topics = 7  has Coherence Value of 0.4221\n",
      "Num Topics = 8  has Coherence Value of 0.4447\n",
      "Num Topics = 9  has Coherence Value of 0.4381\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.110*\"size\" + 0.087*\"fit\" + 0.060*\"small\" + 0.053*\"order\" + 0.038*\"large\" '\n",
      "  '+ 0.034*\"run\" + 0.024*\"petite\" + 0.024*\"medium\" + 0.023*\"big\" + '\n",
      "  '0.020*\"tight\"'),\n",
      " (1,\n",
      "  '0.130*\"dress\" + 0.047*\"make\" + 0.044*\"fabric\" + 0.026*\"beautiful\" + '\n",
      "  '0.025*\"feel\" + 0.021*\"cut\" + 0.019*\"flattering\" + 0.016*\"material\" + '\n",
      "  '0.014*\"line\" + 0.013*\"shape\"'),\n",
      " (2,\n",
      "  '0.101*\"wear\" + 0.044*\"buy\" + 0.044*\"love\" + 0.033*\"great\" + 0.026*\"perfect\" '\n",
      "  '+ 0.025*\"purchase\" + 0.023*\"comfortable\" + 0.021*\"sweater\" + 0.021*\"soft\" + '\n",
      "  '0.021*\"fall\"'),\n",
      " (3,\n",
      "  '0.080*\"top\" + 0.078*\"color\" + 0.029*\"shirt\" + 0.023*\"nice\" + 0.022*\"pretty\" '\n",
      "  '+ 0.021*\"back\" + 0.021*\"sleeve\" + 0.020*\"love\" + 0.018*\"picture\" + '\n",
      "  '0.016*\"detail\"'),\n",
      " (4,\n",
      "  '0.040*\"love\" + 0.036*\"long\" + 0.034*\"great\" + 0.032*\"short\" + '\n",
      "  '0.030*\"length\" + 0.029*\"work\" + 0.026*\"good\" + 0.025*\"waist\" + 0.023*\"pant\" '\n",
      "  '+ 0.023*\"skirt\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3] # canviar pel que vulgui\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>wear, buy, love, great, perfect, purchase, com...</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>wear, buy, love, great, perfect, purchase, com...</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>top, color, shirt, nice, pretty, back, sleeve,...</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>love, long, great, short, length, work, good, ...</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>top, color, shirt, nice, pretty, back, sleeve,...</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>love, long, great, short, length, work, good, ...</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>I love this dress. i usually get an xs but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>I'm 5\"5' and 125 lbs. i ordered the s petite t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             2.0              0.2243   \n",
       "1            1             0.0              0.2355   \n",
       "2            2             0.0              0.2967   \n",
       "3            3             2.0              0.2490   \n",
       "4            4             3.0              0.2344   \n",
       "5            5             4.0              0.2401   \n",
       "6            6             3.0              0.2492   \n",
       "7            7             4.0              0.2439   \n",
       "8            8             0.0              0.2527   \n",
       "9            9             0.0              0.2523   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  wear, buy, love, great, perfect, purchase, com...   \n",
       "1  size, fit, small, order, large, run, petite, m...   \n",
       "2  size, fit, small, order, large, run, petite, m...   \n",
       "3  wear, buy, love, great, perfect, purchase, com...   \n",
       "4  top, color, shirt, nice, pretty, back, sleeve,...   \n",
       "5  love, long, great, short, length, work, good, ...   \n",
       "6  top, color, shirt, nice, pretty, back, sleeve,...   \n",
       "7  love, long, great, short, length, work, good, ...   \n",
       "8  size, fit, small, order, large, run, petite, m...   \n",
       "9  size, fit, small, order, large, run, petite, m...   \n",
       "\n",
       "                                                Text  \n",
       "0  Absolutely wonderful - silky and sexy and comf...  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...  \n",
       "2  I had such high hopes for this dress and reall...  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...  \n",
       "4  This shirt is very flattering to all due to th...  \n",
       "5  I love tracy reese dresses, but this one is no...  \n",
       "6  I aded this in my basket at hte last mintue to...  \n",
       "7  I ordered this in carbon for store pick up, an...  \n",
       "8  I love this dress. i usually get an xs but it ...  \n",
       "9  I'm 5\"5' and 125 lbs. i ordered the s petite t...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df['review_text']):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=df['review_text'])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>wear, buy, love, great, perfect, purchase, com...</td>\n",
       "      <td>4930.0</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>0.1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>5280.0</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>wear, buy, love, great, perfect, purchase, com...</td>\n",
       "      <td>4310.0</td>\n",
       "      <td>0.1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>top, color, shirt, nice, pretty, back, sleeve,...</td>\n",
       "      <td>3851.0</td>\n",
       "      <td>0.1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23458 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dominant_Topic                                     Topic_Keywords  \\\n",
       "0.0                 2.0  wear, buy, love, great, perfect, purchase, com...   \n",
       "1.0                 0.0  size, fit, small, order, large, run, petite, m...   \n",
       "2.0                 0.0  size, fit, small, order, large, run, petite, m...   \n",
       "3.0                 2.0  wear, buy, love, great, perfect, purchase, com...   \n",
       "4.0                 3.0  top, color, shirt, nice, pretty, back, sleeve,...   \n",
       "...                 ...                                                ...   \n",
       "23481.0             NaN                                                NaN   \n",
       "23482.0             NaN                                                NaN   \n",
       "23483.0             NaN                                                NaN   \n",
       "23484.0             NaN                                                NaN   \n",
       "23485.0             NaN                                                NaN   \n",
       "\n",
       "         Num_Documents  Perc_Documents  \n",
       "0.0             4930.0          0.2179  \n",
       "1.0             4257.0          0.1881  \n",
       "2.0             5280.0          0.2333  \n",
       "3.0             4310.0          0.1905  \n",
       "4.0             3851.0          0.1702  \n",
       "...                ...             ...  \n",
       "23481.0            NaN             NaN  \n",
       "23482.0            NaN             NaN  \n",
       "23483.0            NaN             NaN  \n",
       "23484.0            NaN             NaN  \n",
       "23485.0            NaN             NaN  \n",
       "\n",
       "[23458 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>wear, buy, love, great, perfect, purchase, com...</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>size, fit, small, order, large, run, petite, m...</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>wear, buy, love, great, perfect, purchase, com...</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>top, color, shirt, nice, pretty, back, sleeve,...</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             2.0              0.2243   \n",
       "1            1             0.0              0.2355   \n",
       "2            2             0.0              0.2967   \n",
       "3            3             2.0              0.2490   \n",
       "4            4             3.0              0.2344   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  wear, buy, love, great, perfect, purchase, com...   \n",
       "1  size, fit, small, order, large, run, petite, m...   \n",
       "2  size, fit, small, order, large, run, petite, m...   \n",
       "3  wear, buy, love, great, perfect, purchase, com...   \n",
       "4  top, color, shirt, nice, pretty, back, sleeve,...   \n",
       "\n",
       "                                                Text  rating  \n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5  \n",
       "2  I had such high hopes for this dress and reall...       3  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5  \n",
       "4  This shirt is very flattering to all due to th...       5  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(df_dominant_topic, df['rating'], how='inner', left_index=True, right_index=True)\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dominant_Topic  rating\n",
       "0.0             5         2614\n",
       "                4         1011\n",
       "                3          622\n",
       "                2          351\n",
       "                1          165\n",
       "1.0             5         2249\n",
       "                4          912\n",
       "                3          530\n",
       "                2          265\n",
       "                1          137\n",
       "2.0             5         2796\n",
       "                4         1111\n",
       "                3          638\n",
       "                2          341\n",
       "                1          201\n",
       "3.0             5         2320\n",
       "                4          903\n",
       "                3          496\n",
       "                2          289\n",
       "                1          147\n",
       "4.0             5         2119\n",
       "                4          771\n",
       "                3          428\n",
       "                2          236\n",
       "                1          146\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.groupby('Dominant_Topic').rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dominant_Topic\n",
       "0.0    4.166912\n",
       "1.0    4.190081\n",
       "2.0    4.171614\n",
       "3.0    4.193742\n",
       "4.0    4.211081\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.groupby('Dominant_Topic').rating.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    5087\n",
       "0.0    4763\n",
       "3.0    4155\n",
       "1.0    4093\n",
       "4.0    3700\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.Dominant_Topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
