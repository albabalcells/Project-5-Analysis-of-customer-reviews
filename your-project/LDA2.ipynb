{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2: add classes and departments to stop_words and see if it improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following steps from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended</th>\n",
       "      <th>pos_feedback_count</th>\n",
       "      <th>division</th>\n",
       "      <th>department</th>\n",
       "      <th>class</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>review_char</th>\n",
       "      <th>review_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.339583</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>303</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>0.356294</td>\n",
       "      <td>500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>0.512891</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>192</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  age                                        review_text  \\\n",
       "0          767   33  Absolutely wonderful - silky and sexy and comf...   \n",
       "1         1080   34  Love this dress!  it's sooo pretty.  i happene...   \n",
       "2         1077   60  I had such high hopes for this dress and reall...   \n",
       "3         1049   50  I love, love, love this jumpsuit. it's fun, fl...   \n",
       "4          847   47  This shirt is very flattering to all due to th...   \n",
       "\n",
       "   rating  recommended  pos_feedback_count        division department  \\\n",
       "0       4            1                   0       Initmates   Intimate   \n",
       "1       5            1                   4         General    Dresses   \n",
       "2       3            0                   0         General    Dresses   \n",
       "3       5            1                   0  General Petite    Bottoms   \n",
       "4       5            1                   6         General       Tops   \n",
       "\n",
       "       class  polarity  subjectivity  review_char  review_words  sentiment  \n",
       "0  Intimates  0.633333      0.933333           53             8          1  \n",
       "1    Dresses  0.339583      0.725000          303            62          1  \n",
       "2    Dresses  0.073675      0.356294          500            98          1  \n",
       "3      Pants  0.550000      0.625000          124            22          1  \n",
       "4    Blouses  0.512891      0.568750          192            36          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('./data/Womens Clothing E-Commerce Reviews_clean.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intimate', 'Dresses', 'Bottoms', 'Tops', 'Jackets', 'Trend']\n",
      "['Intimates', 'Dresses', 'Pants', 'Blouses', 'Knits', 'Outerwear', 'Lounge', 'Sweaters', 'Skirts', 'Fine gauge', 'Sleep', 'Jackets', 'Swim', 'Trend', 'Jeans', 'Legwear', 'Shorts', 'Layering', 'Casual bottoms', 'Chemises']\n"
     ]
    }
   ],
   "source": [
    "lst_department = list(df.department.unique())\n",
    "lst_class = list(df['class'].unique())\n",
    "\n",
    "print(lst_department)\n",
    "print(lst_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'and', 'dress', 'top',\n",
    "                   'jacket', 'pants', 'blouse', 'sweater', 'skirt', 'jeans', 'shorts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(df['review_text']))\n",
    "\n",
    "print(data_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'wonderful', 'silky', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
    "\n",
    "For example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n",
    "\n",
    "This is used as the input by the LDA model.\n",
    "\n",
    "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absolutely'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('absolutely', 1), ('comfortable', 1), ('silky', 1), ('wonderful', 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.065*\"beautiful\" + 0.047*\"even\" + 0.044*\"cut\" + 0.040*\"return\" + '\n",
      "  '0.036*\"design\" + 0.032*\"shoulder\" + 0.029*\"review\" + 0.026*\"line\" + '\n",
      "  '0.016*\"unique\" + 0.016*\"happy\"'),\n",
      " (1,\n",
      "  '0.075*\"wear\" + 0.069*\"love\" + 0.046*\"great\" + 0.032*\"buy\" + '\n",
      "  '0.028*\"flattering\" + 0.027*\"perfect\" + 0.025*\"soft\" + 0.024*\"long\" + '\n",
      "  '0.023*\"comfortable\" + 0.023*\"work\"'),\n",
      " (2,\n",
      "  '0.152*\"color\" + 0.050*\"purchase\" + 0.040*\"black\" + 0.026*\"print\" + '\n",
      "  '0.025*\"gorgeous\" + 0.024*\"light\" + 0.023*\"different\" + 0.021*\"blue\" + '\n",
      "  '0.021*\"see\" + 0.020*\"white\"'),\n",
      " (3,\n",
      "  '0.049*\"low\" + 0.045*\"thick\" + 0.042*\"wash\" + 0.028*\"denim\" + 0.027*\"cover\" '\n",
      "  '+ 0.025*\"cotton\" + 0.023*\"cami\" + 0.020*\"flat\" + 0.020*\"season\" + '\n",
      "  '0.020*\"skin\"'),\n",
      " (4,\n",
      "  '0.083*\"waist\" + 0.043*\"pattern\" + 0.033*\"body\" + 0.028*\"hip\" + '\n",
      "  '0.025*\"figure\" + 0.023*\"tank\" + 0.022*\"leg\" + 0.018*\"problem\" + 0.016*\"put\" '\n",
      "  '+ 0.016*\"part\"'),\n",
      " (5,\n",
      "  '0.080*\"look\" + 0.043*\"would\" + 0.042*\"fabric\" + 0.035*\"well\" + 0.035*\"make\" '\n",
      "  '+ 0.029*\"really\" + 0.028*\"feel\" + 0.026*\"much\" + 0.026*\"material\" + '\n",
      "  '0.023*\"think\"'),\n",
      " (6,\n",
      "  '0.073*\"size\" + 0.058*\"fit\" + 0.041*\"small\" + 0.032*\"order\" + 0.028*\"go\" + '\n",
      "  '0.027*\"little\" + 0.026*\"get\" + 0.026*\"try\" + 0.025*\"large\" + 0.023*\"run\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.689991362231533\n",
      "\n",
      "Coherence Score:  0.3663307090497413\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el950253451928645754841709\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el950253451928645754841709_data = {\"mdsDat\": {\"x\": [-0.2340467690356292, -0.17695749686085907, -0.22754907240327807, 0.18082515756253642, 0.09449072332374195, 0.19265734866270884, 0.1705801087507792], \"y\": [0.23375074105140423, -0.36822844430474866, 0.04777818250116631, -0.051275461338005514, 0.1749171565009554, -0.024226402518683826, -0.012715771892087656], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [26.955095291137695, 25.234376907348633, 21.823820114135742, 8.887336730957031, 8.58355712890625, 5.552508354187012, 2.9633076190948486]}, \"tinfo\": {\"Term\": [\"color\", \"look\", \"wear\", \"size\", \"love\", \"fit\", \"great\", \"small\", \"fabric\", \"beautiful\", \"waist\", \"would\", \"make\", \"order\", \"well\", \"buy\", \"purchase\", \"even\", \"go\", \"really\", \"flattering\", \"little\", \"cut\", \"perfect\", \"try\", \"feel\", \"soft\", \"large\", \"much\", \"material\", \"size\", \"small\", \"order\", \"go\", \"little\", \"try\", \"large\", \"run\", \"bit\", \"petite\", \"find\", \"big\", \"medium\", \"quality\", \"retailer\", \"store\", \"still\", \"tight\", \"usually\", \"true\", \"could\", \"price\", \"sale\", \"may\", \"definitely\", \"lbs\", \"keep\", \"loose\", \"regular\", \"seem\", \"fit\", \"pretty\", \"get\", \"nice\", \"say\", \"wear\", \"love\", \"great\", \"buy\", \"perfect\", \"soft\", \"long\", \"flattering\", \"comfortable\", \"work\", \"length\", \"sleeve\", \"style\", \"fall\", \"perfectly\", \"right\", \"super\", \"dress\", \"pair\", \"enough\", \"summer\", \"time\", \"piece\", \"many\", \"day\", \"casual\", \"compliment\", \"first\", \"receive\", \"legging\", \"give\", \"shirt\", \"need\", \"short\", \"look\", \"fabric\", \"make\", \"really\", \"much\", \"material\", \"good\", \"also\", \"back\", \"way\", \"picture\", \"model\", \"online\", \"however\", \"side\", \"front\", \"person\", \"thin\", \"arm\", \"show\", \"tall\", \"wide\", \"almost\", \"thing\", \"slightly\", \"hang\", \"actually\", \"reviewer\", \"easy\", \"like\", \"want\", \"well\", \"feel\", \"cute\", \"would\", \"shape\", \"think\", \"bottom\", \"short\", \"see\", \"beautiful\", \"even\", \"cut\", \"return\", \"shoulder\", \"review\", \"line\", \"unique\", \"happy\", \"area\", \"unfortunately\", \"tee\", \"pocket\", \"decide\", \"embroidery\", \"year\", \"frame\", \"item\", \"bad\", \"dressy\", \"note\", \"disappoint\", \"read\", \"touch\", \"less\", \"strap\", \"hard\", \"girl\", \"rather\", \"clothing\", \"design\", \"wish\", \"color\", \"purchase\", \"black\", \"print\", \"gorgeous\", \"light\", \"different\", \"blue\", \"white\", \"recommend\", \"absolutely\", \"sheer\", \"boot\", \"boxy\", \"knee\", \"end\", \"red\", \"glad\", \"flowy\", \"thought\", \"adorable\", \"dark\", \"green\", \"lightweight\", \"extremely\", \"favorite\", \"one\", \"feminine\", \"sizing\", \"pink\", \"see\", \"waist\", \"pattern\", \"body\", \"hip\", \"figure\", \"tank\", \"leg\", \"problem\", \"put\", \"part\", \"knit\", \"tie\", \"type\", \"ankle\", \"agree\", \"other\", \"curve\", \"flare\", \"help\", \"straight\", \"open\", \"complaint\", \"tell\", \"slim\", \"suit\", \"torso\", \"hide\", \"romper\", \"adjustable\", \"zip\", \"low\", \"thick\", \"wash\", \"denim\", \"cover\", \"cotton\", \"cami\", \"flat\", \"season\", \"skin\", \"incredibly\", \"woman\", \"armhole\", \"walk\", \"slit\", \"rise\", \"sandal\", \"amount\", \"worry\", \"subtle\", \"flower\", \"become\", \"lay\", \"closet\", \"dry\", \"draw\", \"old\", \"stiff\", \"sort\", \"barely\"], \"Freq\": [6886.0, 9236.0, 9932.0, 10315.0, 9234.0, 8369.0, 6123.0, 5811.0, 4822.0, 3023.0, 2414.0, 5444.0, 4004.0, 4603.0, 4069.0, 4192.0, 2268.0, 2181.0, 4012.0, 3341.0, 3664.0, 3809.0, 2044.0, 3547.0, 3663.0, 3308.0, 3351.0, 3486.0, 2984.0, 2979.0, 10314.8203125, 5810.845703125, 4602.88720703125, 4011.90478515625, 3808.894287109375, 3662.4814453125, 3485.65771484375, 3237.44189453125, 2794.490966796875, 2471.888671875, 2291.61767578125, 2192.1142578125, 2169.50732421875, 2118.302734375, 2104.252197265625, 2073.05224609375, 1852.9500732421875, 1845.98681640625, 1831.72900390625, 1798.271728515625, 1683.7835693359375, 1655.7249755859375, 1608.55029296875, 1504.0887451171875, 1264.4798583984375, 1240.5281982421875, 1195.025390625, 1153.23828125, 1093.7232666015625, 1085.203857421875, 8272.330078125, 2221.185302734375, 3680.665283203125, 2657.47216796875, 1382.5037841796875, 9931.5703125, 9233.34375, 6122.24755859375, 4191.94091796875, 3546.743896484375, 3350.590576171875, 3195.675048828125, 3663.32763671875, 3080.527587890625, 3057.925048828125, 3007.41064453125, 2216.00634765625, 1793.767822265625, 1739.717529296875, 1642.3248291015625, 1635.2734375, 1582.8807373046875, 1516.7890625, 1395.154541015625, 1367.2984619140625, 1323.8409423828125, 1310.8319091796875, 1182.6533203125, 1138.6417236328125, 1116.9080810546875, 1113.8184814453125, 1018.2667846679688, 1013.150146484375, 976.947265625, 965.2062377929688, 1192.5882568359375, 1672.8438720703125, 1110.2451171875, 1034.4005126953125, 9235.578125, 4821.9453125, 4003.80419921875, 3340.94580078125, 2983.2744140625, 2978.191650390625, 2571.997314453125, 2521.5986328125, 2498.4931640625, 2160.43359375, 1700.8861083984375, 1499.302978515625, 1475.30419921875, 1435.9476318359375, 1432.8790283203125, 1296.7578125, 1287.72509765625, 1114.6536865234375, 1086.2451171875, 970.5230712890625, 814.5538330078125, 808.6719360351562, 788.7861938476562, 779.2727661132812, 771.8074340820312, 746.4107666015625, 719.085693359375, 699.9219970703125, 696.4041137695312, 672.6613159179688, 2045.0672607421875, 4019.631103515625, 3251.559326171875, 2609.338134765625, 4953.78955078125, 968.3258056640625, 2648.828125, 1124.1107177734375, 1087.4378662109375, 891.1235961914062, 3022.244873046875, 2180.373779296875, 2043.51611328125, 1856.2666015625, 1519.5374755859375, 1350.7828369140625, 1224.99755859375, 746.5010986328125, 742.111572265625, 701.80712890625, 688.7164916992188, 584.3289794921875, 526.2364501953125, 518.0805053710938, 471.9433898925781, 428.3957214355469, 415.39520263671875, 412.7297058105469, 349.45166015625, 348.9053039550781, 346.1822204589844, 341.52374267578125, 334.0867614746094, 333.8085021972656, 333.23101806640625, 319.7074279785156, 319.0716247558594, 318.5672912597656, 311.9308166503906, 305.79876708984375, 1668.3992919921875, 714.2555541992188, 6885.51318359375, 2267.822998046875, 1791.3751220703125, 1161.014404296875, 1145.6064453125, 1101.30224609375, 1030.5042724609375, 959.5931396484375, 889.9118041992188, 746.8385620117188, 738.6841430664062, 711.3493041992188, 669.9708251953125, 620.9061889648438, 616.3801879882812, 560.3193359375, 540.2979736328125, 537.8560180664062, 524.1314086914062, 511.951416015625, 508.1002197265625, 500.77545166015625, 463.7536315917969, 458.1774597167969, 434.9557189941406, 434.1865234375, 377.0302429199219, 367.3932189941406, 366.177490234375, 346.45220947265625, 944.267578125, 2413.659912109375, 1267.795166015625, 954.579833984375, 825.4855346679688, 721.3212890625, 673.4745483398438, 653.398681640625, 516.29052734375, 476.59027099609375, 469.3065490722656, 456.6357727050781, 449.49072265625, 431.4819030761719, 403.5172119140625, 371.62060546875, 347.1464538574219, 335.34027099609375, 329.5515441894531, 325.8411865234375, 290.7106628417969, 287.69439697265625, 283.1507263183594, 275.34710693359375, 262.17498779296875, 258.8851318359375, 254.61294555664062, 232.46768188476562, 229.3618927001953, 220.68563842773438, 218.65533447265625, 761.4027709960938, 706.4939575195312, 650.0628662109375, 442.4896545410156, 414.3402099609375, 387.47943115234375, 360.7151794433594, 319.09661865234375, 310.21826171875, 304.5007019042969, 291.55377197265625, 287.38623046875, 280.74755859375, 272.0095520019531, 260.2845458984375, 254.3633270263672, 242.07176208496094, 239.49896240234375, 196.2301483154297, 187.82167053222656, 180.15232849121094, 178.9090576171875, 168.03848266601562, 163.79583740234375, 163.64810180664062, 163.37063598632812, 158.76705932617188, 153.35458374023438, 143.3185577392578, 141.73007202148438], \"Total\": [6886.0, 9236.0, 9932.0, 10315.0, 9234.0, 8369.0, 6123.0, 5811.0, 4822.0, 3023.0, 2414.0, 5444.0, 4004.0, 4603.0, 4069.0, 4192.0, 2268.0, 2181.0, 4012.0, 3341.0, 3664.0, 3809.0, 2044.0, 3547.0, 3663.0, 3308.0, 3351.0, 3486.0, 2984.0, 2979.0, 10315.6728515625, 5811.69921875, 4603.74072265625, 4012.758544921875, 3809.747802734375, 3663.335205078125, 3486.5107421875, 3238.294921875, 2795.3447265625, 2472.7421875, 2292.471923828125, 2192.967529296875, 2170.3603515625, 2119.15576171875, 2105.105224609375, 2073.905517578125, 1853.8037109375, 1846.8408203125, 1832.5821533203125, 1799.1253662109375, 1684.636962890625, 1656.57861328125, 1609.4044189453125, 1504.942138671875, 1265.3331298828125, 1241.3814697265625, 1195.8782958984375, 1154.091552734375, 1094.576416015625, 1086.0572509765625, 8369.33203125, 2232.536376953125, 3882.381591796875, 2895.8251953125, 1570.3074951171875, 9932.4228515625, 9234.1962890625, 6123.1005859375, 4192.79443359375, 3547.597412109375, 3351.444091796875, 3196.528564453125, 3664.3291015625, 3081.380615234375, 3058.77880859375, 3008.26416015625, 2216.8603515625, 1794.6212158203125, 1740.5706787109375, 1643.17822265625, 1636.127197265625, 1583.7337646484375, 1517.6429443359375, 1396.0079345703125, 1368.15185546875, 1324.6939697265625, 1311.685302734375, 1183.506591796875, 1139.4952392578125, 1117.761474609375, 1114.6722412109375, 1019.1195068359375, 1014.0036010742188, 977.8004760742188, 966.0595703125, 1249.6427001953125, 2331.947998046875, 1219.9744873046875, 2122.54833984375, 9236.4306640625, 4822.7978515625, 4004.656982421875, 3341.7978515625, 2984.127197265625, 2979.097900390625, 2572.85205078125, 2522.451416015625, 2499.344970703125, 2161.286865234375, 1701.7386474609375, 1500.155517578125, 1476.1568603515625, 1436.7999267578125, 1433.731689453125, 1297.6104736328125, 1288.5775146484375, 1115.5068359375, 1087.097412109375, 971.3751831054688, 815.4069213867188, 809.524658203125, 789.6390991210938, 780.1251831054688, 772.6603393554688, 747.2640991210938, 719.9385986328125, 700.7749633789062, 697.2570190429688, 673.5136108398438, 2049.9541015625, 4069.21240234375, 3308.632568359375, 2717.116943359375, 5444.7890625, 980.4876708984375, 2933.869873046875, 1584.2574462890625, 2122.54833984375, 2954.011474609375, 3023.097412109375, 2181.225830078125, 2044.368896484375, 1857.118896484375, 1520.3902587890625, 1351.6357421875, 1225.849853515625, 747.3534545898438, 742.96435546875, 702.6593017578125, 689.5687255859375, 585.180419921875, 527.087890625, 518.9322509765625, 472.79620361328125, 429.2477722167969, 416.247314453125, 413.5815734863281, 350.30303955078125, 349.7583312988281, 347.0350341796875, 342.37542724609375, 334.9385070800781, 334.6612243652344, 334.08349609375, 320.5604553222656, 319.9235534667969, 319.42010498046875, 312.7832336425781, 306.6520080566406, 1707.5831298828125, 753.352294921875, 6886.369140625, 2268.678955078125, 1792.2313232421875, 1161.871337890625, 1146.4625244140625, 1102.15869140625, 1031.3612060546875, 960.4485473632812, 890.7673950195312, 747.6951904296875, 739.540283203125, 712.2064208984375, 670.8275756835938, 621.7619018554688, 617.2369995117188, 561.175537109375, 541.1536865234375, 538.7135009765625, 524.9874267578125, 512.8084106445312, 508.9566650390625, 501.63104248046875, 464.60894775390625, 459.03472900390625, 435.8123474121094, 435.04254150390625, 377.88671875, 368.2500305175781, 367.0339050292969, 347.30755615234375, 2954.011474609375, 2414.514892578125, 1268.650634765625, 955.4342651367188, 826.3397827148438, 722.177001953125, 674.3289794921875, 654.2531127929688, 517.1453247070312, 477.4452209472656, 470.16094970703125, 457.49127197265625, 450.3456726074219, 432.3367919921875, 404.3726806640625, 372.4754638671875, 348.00335693359375, 336.1954345703125, 330.4076843261719, 326.69659423828125, 291.5650329589844, 288.54833984375, 284.0075988769531, 276.2021789550781, 263.0299987792969, 259.73907470703125, 255.46775817871094, 233.32192993164062, 230.21803283691406, 221.54458618164062, 219.5105743408203, 762.2569580078125, 707.3482666015625, 650.9164428710938, 443.34393310546875, 415.1953125, 388.333251953125, 361.5697021484375, 319.95013427734375, 311.07318115234375, 305.355224609375, 292.4091491699219, 288.2405090332031, 281.6015930175781, 272.86492919921875, 261.1393127441406, 255.21742248535156, 242.92645263671875, 240.35308837890625, 197.08555603027344, 188.67640686035156, 181.00662231445312, 179.76385498046875, 168.8928985595703, 164.649658203125, 164.5012969970703, 164.2266845703125, 159.621337890625, 154.20849609375, 144.17283630371094, 142.583740234375], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.622299909591675, -3.1960999965667725, -3.4291999340057373, -3.5666000843048096, -3.618499994277954, -3.6577000617980957, -3.707200050354004, -3.781100034713745, -3.9282000064849854, -4.050899982452393, -4.1265997886657715, -4.171000003814697, -4.181300163269043, -4.2052001953125, -4.211900234222412, -4.226799964904785, -4.339099884033203, -4.342800140380859, -4.350599765777588, -4.36899995803833, -4.434800148010254, -4.451600074768066, -4.480500221252441, -4.547699928283691, -4.721199989318848, -4.740300178527832, -4.777699947357178, -4.813300132751465, -4.866300106048584, -4.874100208282471, -2.842900037765503, -4.157800197601318, -3.6528000831604004, -3.9784998893737793, -4.631899833679199, -2.5941998958587646, -2.667099952697754, -3.077899932861328, -3.456700086593628, -3.623800039291382, -3.6807000637054443, -3.728100061416626, -3.5915000438690186, -3.7648000717163086, -3.7720999717712402, -3.788800001144409, -4.094200134277344, -4.305600166320801, -4.33620023727417, -4.393799781799316, -4.398099899291992, -4.430600166320801, -4.473299980163574, -4.5569000244140625, -4.577000141143799, -4.609300136566162, -4.619200229644775, -4.722099781036377, -4.760000228881836, -4.779300212860107, -4.782100200653076, -4.871799945831299, -4.876800060272217, -4.9131999015808105, -4.925300121307373, -4.713799953460693, -4.375400066375732, -4.785299777984619, -4.856100082397461, -2.5216000080108643, -3.1714999675750732, -3.3573999404907227, -3.5383999347686768, -3.651700019836426, -3.65339994430542, -3.799999952316284, -3.8197999000549316, -3.8289999961853027, -3.974400043487549, -4.213500022888184, -4.339700222015381, -4.355800151824951, -4.382800102233887, -4.385000228881836, -4.484799861907959, -4.491799831390381, -4.636099815368652, -4.661900043487549, -4.774600028991699, -4.94980001449585, -4.956999778747559, -4.981900215148926, -4.994100093841553, -5.003699779510498, -5.037199974060059, -5.074399948120117, -5.101500034332275, -5.106500148773193, -5.141200065612793, -4.029200077056885, -3.3534998893737793, -3.565500020980835, -3.785599946975708, -3.1445000171661377, -4.776899814605713, -3.7706000804901123, -4.627699851989746, -4.660799980163574, -4.859899997711182, -2.740299940109253, -3.066800117492676, -3.1315999031066895, -3.2276999950408936, -3.4279000759124756, -3.545599937438965, -3.643399953842163, -4.138700008392334, -4.144599914550781, -4.200399875640869, -4.219200134277344, -4.383600234985352, -4.48829984664917, -4.503900051116943, -4.5971999168396, -4.693999767303467, -4.724800109863281, -4.731299877166748, -4.89769983291626, -4.8993000984191895, -4.907100200653076, -4.920599937438965, -4.942699909210205, -4.94350004196167, -4.945199966430664, -4.986599922180176, -4.98859977722168, -4.990200042724609, -5.011300086975098, -5.031099796295166, -3.334399938583374, -4.182799816131592, -1.882099986076355, -2.9927000999450684, -3.2284998893737793, -3.6621999740600586, -3.675600051879883, -3.7149999141693115, -3.7815001010894775, -3.852799892425537, -3.9282000064849854, -4.103400230407715, -4.1143999099731445, -4.152100086212158, -4.211999893188477, -4.288099765777588, -4.295400142669678, -4.3907999992370605, -4.427199840545654, -4.431700229644775, -4.457499980926514, -4.480999946594238, -4.48859977722168, -4.5030999183654785, -4.579899787902832, -4.5920000076293945, -4.644000053405762, -4.6458001136779785, -4.786900043487549, -4.81279993057251, -4.816199779510498, -4.871500015258789, -3.8689000606536865, -2.494800090789795, -3.1386001110076904, -3.4223999977111816, -3.567699909210205, -3.7026000022888184, -3.771199941635132, -3.801500082015991, -4.0370001792907715, -4.117000102996826, -4.132400035858154, -4.159800052642822, -4.175600051879883, -4.2164998054504395, -4.2835001945495605, -4.365799903869629, -4.433899879455566, -4.468500137329102, -4.485899925231934, -4.497300148010254, -4.611299991607666, -4.621799945831299, -4.637700080871582, -4.665599822998047, -4.714700222015381, -4.72730016708374, -4.743899822235107, -4.83489990234375, -4.848400115966797, -4.886899948120117, -4.896200180053711, -3.0206000804901123, -3.095400094985962, -3.1786999702453613, -3.5632998943328857, -3.628999948501587, -3.6960999965667725, -3.7676000595092773, -3.890199899673462, -3.9184999465942383, -3.9370999336242676, -3.9804999828338623, -3.9948999881744385, -4.0183000564575195, -4.049900054931641, -4.093999862670898, -4.117000102996826, -4.166500091552734, -4.177199840545654, -4.376399993896484, -4.420199871063232, -4.461900234222412, -4.468900203704834, -4.531499862670898, -4.55709981918335, -4.558000087738037, -4.559700012207031, -4.5883002281188965, -4.623000144958496, -4.690700054168701, -4.7017998695373535], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3108999729156494, 1.3108999729156494, 1.3107999563217163, 1.3107999563217163, 1.3107999563217163, 1.3107999563217163, 1.3107999563217163, 1.3107000589370728, 1.3107000589370728, 1.3107000589370728, 1.3106000423431396, 1.3106000423431396, 1.3106000423431396, 1.3106000423431396, 1.3106000423431396, 1.3106000423431396, 1.3105000257492065, 1.3105000257492065, 1.3105000257492065, 1.3105000257492065, 1.3105000257492065, 1.3105000257492065, 1.3105000257492065, 1.3104000091552734, 1.3102999925613403, 1.3102999925613403, 1.3102999925613403, 1.3102999925613403, 1.3101999759674072, 1.3101999759674072, 1.299299955368042, 1.305899977684021, 1.257599949836731, 1.225100040435791, 1.1835999488830566, 1.3768999576568604, 1.3768999576568604, 1.3767999410629272, 1.3767999410629272, 1.3767000436782837, 1.3767000436782837, 1.3767000436782837, 1.3767000436782837, 1.3767000436782837, 1.3767000436782837, 1.3767000436782837, 1.3766000270843506, 1.3765000104904175, 1.3765000104904175, 1.3763999938964844, 1.3763999938964844, 1.3763999938964844, 1.3763999938964844, 1.3763999938964844, 1.3762999773025513, 1.3762999773025513, 1.3762999773025513, 1.3761999607086182, 1.3761999607086182, 1.3761999607086182, 1.3761999607086182, 1.376099944114685, 1.376099944114685, 1.376099944114685, 1.376099944114685, 1.330199956893921, 1.044800043106079, 1.2826999425888062, 0.6582000255584717, 1.5220999717712402, 1.5219999551773071, 1.5219999551773071, 1.5219000577926636, 1.5219000577926636, 1.5219000577926636, 1.5218000411987305, 1.5218000411987305, 1.5218000411987305, 1.5218000411987305, 1.5217000246047974, 1.5216000080108643, 1.5216000080108643, 1.5216000080108643, 1.5216000080108643, 1.5214999914169312, 1.5214999914169312, 1.521399974822998, 1.521399974822998, 1.521299958229065, 1.5211000442504883, 1.5211000442504883, 1.5211000442504883, 1.5211000442504883, 1.5211000442504883, 1.5210000276565552, 1.5210000276565552, 1.5210000276565552, 1.520900011062622, 1.520900011062622, 1.5197999477386475, 1.5098999738693237, 1.5047999620437622, 1.4816999435424805, 1.4277000427246094, 1.5096999406814575, 1.4199999570846558, 1.1790000200271606, 0.8533999919891357, 0.3237000107765198, 2.420300006866455, 2.4202001094818115, 2.420099973678589, 2.420099973678589, 2.4200000762939453, 2.4198999404907227, 2.419800043106079, 2.4193999767303467, 2.4193999767303467, 2.419300079345703, 2.419300079345703, 2.419100046157837, 2.4189000129699707, 2.4189000129699707, 2.4186999797821045, 2.418600082397461, 2.4184999465942383, 2.4184999465942383, 2.418100118637085, 2.418100118637085, 2.418100118637085, 2.418100118637085, 2.4179999828338623, 2.4179999828338623, 2.4179999828338623, 2.4179000854492188, 2.4179000854492188, 2.4179000854492188, 2.417799949645996, 2.417799949645996, 2.3973000049591064, 2.367300033569336, 2.455199956893921, 2.454900026321411, 2.4547998905181885, 2.4546000957489014, 2.4546000957489014, 2.4544999599456787, 2.4544999599456787, 2.454400062561035, 2.454400062561035, 2.454200029373169, 2.454200029373169, 2.4540998935699463, 2.4539999961853027, 2.453900098800659, 2.453900098800659, 2.4537999629974365, 2.453700065612793, 2.453700065612793, 2.453700065612793, 2.4535999298095703, 2.4535999298095703, 2.4535999298095703, 2.4535000324249268, 2.4535000324249268, 2.453399896621704, 2.453399896621704, 2.4530999660491943, 2.453000068664551, 2.453000068664551, 2.452899932861328, 1.3148000240325928, 2.8905999660491943, 2.890199899673462, 2.890000104904175, 2.889899969100952, 2.889699935913086, 2.889699935913086, 2.8896000385284424, 2.8893001079559326, 2.8891000747680664, 2.8891000747680664, 2.8889999389648438, 2.8889999389648438, 2.8889000415802, 2.8887999057769775, 2.8886001110076904, 2.8884999752044678, 2.888400077819824, 2.8882999420166016, 2.8882999420166016, 2.888000011444092, 2.888000011444092, 2.8879001140594482, 2.8877999782562256, 2.887700080871582, 2.8875999450683594, 2.8875999450683594, 2.8873000144958496, 2.887200117111206, 2.88700008392334, 2.88700008392334, 3.517699956893921, 3.517699956893921, 3.5176000595092773, 3.516900062561035, 3.5167999267578125, 3.516700029373169, 3.5164999961853027, 3.516200065612793, 3.5160999298095703, 3.5160999298095703, 3.515899896621704, 3.515899896621704, 3.5157999992370605, 3.515700101852417, 3.5155999660491943, 3.515500068664551, 3.5153000354766846, 3.5153000354766846, 3.5144999027252197, 3.5143001079559326, 3.5141000747680664, 3.5141000747680664, 3.5137999057769775, 3.513700008392334, 3.513700008392334, 3.5136001110076904, 3.5134999752044678, 3.5132999420166016, 3.5129001140594482, 3.5129001140594482]}, \"token.table\": {\"Topic\": [5, 3, 6, 5, 6, 3, 3, 7, 6, 4, 3, 7, 3, 4, 7, 4, 7, 1, 1, 5, 5, 6, 5, 1, 3, 5, 2, 7, 2, 7, 4, 5, 2, 6, 2, 7, 1, 7, 6, 4, 1, 3, 5, 2, 4, 1, 7, 1, 3, 4, 5, 4, 7, 2, 4, 7, 3, 4, 5, 2, 4, 5, 3, 2, 5, 2, 3, 5, 6, 1, 2, 1, 2, 6, 7, 2, 7, 5, 4, 3, 1, 2, 4, 2, 3, 5, 1, 3, 5, 2, 5, 3, 4, 4, 6, 6, 6, 3, 7, 4, 1, 5, 6, 1, 7, 1, 6, 2, 2, 4, 5, 5, 3, 4, 1, 2, 3, 1, 2, 7, 3, 2, 3, 1, 1, 3, 3, 1, 2, 1, 2, 4, 7, 5, 3, 6, 1, 6, 2, 6, 6, 2, 2, 3, 1, 3, 2, 5, 4, 1, 3, 1, 5, 6, 5, 6, 1, 4, 4, 3, 2, 5, 5, 1, 1, 4, 4, 3, 2, 7, 6, 1, 1, 7, 1, 3, 7, 1, 3, 5, 1, 1, 3, 5, 2, 3, 2, 3, 4, 3, 3, 1, 5, 7, 2, 3, 6, 7, 1, 2, 7, 7, 1, 1, 6, 4, 2, 7, 6, 2, 2, 3, 6, 4, 6, 7, 3, 3, 1, 3, 5, 6, 1, 2, 6, 4, 1, 1, 6, 4, 4, 1, 6, 7, 1, 3, 7, 3, 2, 1, 3, 5, 3, 1, 4, 7, 2, 7, 1, 3, 4, 6], \"Freq\": [0.999269425868988, 0.9986962676048279, 0.9975418448448181, 0.9981203675270081, 0.9987235069274902, 0.999190628528595, 0.9998210668563843, 0.9943704009056091, 0.9990783929824829, 0.9990617036819458, 0.998990535736084, 0.9978636503219604, 0.9994618892669678, 0.9962802529335022, 0.9959059953689575, 0.9996370077133179, 0.9957507848739624, 0.9995588064193726, 0.9995189309120178, 0.9993129372596741, 0.9995329976081848, 0.9995454549789429, 0.9987663626670837, 0.2897256314754486, 0.7094806432723999, 0.9987745881080627, 0.999810516834259, 0.9984243512153625, 0.9993969202041626, 0.9960542917251587, 0.9978737831115723, 0.9999464154243469, 0.9998764991760254, 0.9964522123336792, 0.9989014863967896, 0.9965667128562927, 0.9996219277381897, 0.9971210956573486, 0.9964442253112793, 0.9998195767402649, 0.03937997668981552, 0.9602089524269104, 0.9987420439720154, 0.9993187785148621, 0.9982035160064697, 0.9989464282989502, 0.9969686269760132, 0.014054952189326286, 0.008784345351159573, 0.9768192172050476, 0.9996497631072998, 0.9989034533500671, 0.9925305247306824, 0.9995763301849365, 0.9978318214416504, 0.9969526529312134, 0.9981971979141235, 0.9983159899711609, 0.9979051947593689, 0.9991580843925476, 0.9994379878044128, 0.998136043548584, 0.9998345375061035, 0.9996721148490906, 0.9976035952568054, 0.016925420612096786, 0.9828833937644958, 0.9966054558753967, 0.9983702301979065, 0.9997941255569458, 0.9990102648735046, 0.988370418548584, 0.011470449157059193, 0.9987661242485046, 0.9970303773880005, 0.9996373057365417, 0.9944387674331665, 0.9981191158294678, 0.997003436088562, 0.9995295405387878, 0.9481293559074402, 0.0517723448574543, 0.9986847639083862, 0.9546728730201721, 0.04481280967593193, 0.998675525188446, 0.9998109936714172, 0.9996688365936279, 0.9995965361595154, 0.9998202323913574, 0.9986893534660339, 0.9983083605766296, 0.9987019896507263, 0.9971132278442383, 0.99786776304245, 0.9943342804908752, 0.9983786344528198, 0.9994432330131531, 0.9986007809638977, 0.998593807220459, 0.9992655515670776, 0.997995913028717, 0.9989261627197266, 0.9998534917831421, 0.9947132468223572, 0.9996926784515381, 0.9980846643447876, 0.998903214931488, 0.9995797872543335, 0.9967567920684814, 0.9989486932754517, 0.9977458715438843, 0.9992374181747437, 0.9993067383766174, 0.9998037219047546, 0.9998346567153931, 0.9999533891677856, 0.9990541934967041, 0.9998704791069031, 0.998350977897644, 0.9998359680175781, 0.9995653629302979, 0.9996314644813538, 0.9993739724159241, 0.9998339414596558, 0.9992297291755676, 0.9996222853660583, 0.08934613317251205, 0.90985506772995, 0.9175277352333069, 0.08218728005886078, 0.997017502784729, 0.9961073994636536, 0.9976534843444824, 0.9992163181304932, 0.998099684715271, 0.9998391270637512, 0.9971168041229248, 0.9992780089378357, 0.9975307583808899, 0.9994871616363525, 0.9998316168785095, 0.999282956123352, 0.9995518326759338, 0.9996998310089111, 0.9995659589767456, 0.9995719790458679, 0.996235191822052, 0.9979360103607178, 0.9948326349258423, 0.004927131347358227, 0.9996507167816162, 0.999250054359436, 0.9977852702140808, 0.9997007250785828, 0.999067485332489, 0.9994546175003052, 0.9974959492683411, 0.9971979856491089, 0.9997612237930298, 0.99918133020401, 0.9990702271461487, 0.9978681206703186, 0.9994733929634094, 0.9994750022888184, 0.9993975162506104, 0.9995296597480774, 0.9988941550254822, 0.9993110299110413, 0.9952298402786255, 0.9947091937065125, 0.9996001124382019, 0.999748706817627, 0.9961862564086914, 0.8807192444801331, 0.11908495426177979, 0.9965500831604004, 0.37846839427948, 0.30162373185157776, 0.31956544518470764, 0.9990265369415283, 0.011218907311558723, 0.9872637987136841, 0.9983060956001282, 0.7174259424209595, 0.28216752409935, 0.48715028166770935, 0.512120246887207, 0.9997433423995972, 0.9996137619018555, 0.9994896650314331, 0.9999347925186157, 0.997183084487915, 0.9988366961479187, 0.9996119141578674, 0.9991453886032104, 0.9960840940475464, 0.9956371188163757, 0.9998796582221985, 0.9998674988746643, 0.9918650388717651, 0.9921632409095764, 0.9995664358139038, 0.9995633959770203, 0.9980620741844177, 0.9982516169548035, 0.9996538162231445, 0.9964150190353394, 0.9971545338630676, 0.9994761347770691, 0.9995366930961609, 0.9995009303092957, 0.9980291724205017, 0.9979828000068665, 0.9956474900245667, 0.9980939030647278, 0.9995456337928772, 0.9985576868057251, 0.09680047631263733, 0.9029030203819275, 0.9984235763549805, 0.9970118999481201, 0.9995447397232056, 0.9994775652885437, 0.9981690049171448, 0.9980242252349854, 0.999374508857727, 0.9996355175971985, 0.9969080090522766, 0.9991752505302429, 0.9995270371437073, 0.9996823072433472, 0.9997867345809937, 0.9968301653862, 0.0019512631697580218, 0.9975833296775818, 0.9985920786857605, 0.9994046092033386, 0.9999574422836304, 0.01204164233058691, 0.9879061579704285, 0.9991384744644165, 0.9993519186973572, 0.050441209226846695, 0.9477637410163879, 0.9956962466239929, 0.9997453689575195, 0.9944919347763062, 0.08999430388212204, 0.9098607897758484, 0.997093141078949, 0.9976740479469299], \"Term\": [\"absolutely\", \"actually\", \"adjustable\", \"adorable\", \"agree\", \"almost\", \"also\", \"amount\", \"ankle\", \"area\", \"arm\", \"armhole\", \"back\", \"bad\", \"barely\", \"beautiful\", \"become\", \"big\", \"bit\", \"black\", \"blue\", \"body\", \"boot\", \"bottom\", \"bottom\", \"boxy\", \"buy\", \"cami\", \"casual\", \"closet\", \"clothing\", \"color\", \"comfortable\", \"complaint\", \"compliment\", \"cotton\", \"could\", \"cover\", \"curve\", \"cut\", \"cute\", \"cute\", \"dark\", \"day\", \"decide\", \"definitely\", \"denim\", \"design\", \"design\", \"design\", \"different\", \"disappoint\", \"draw\", \"dress\", \"dressy\", \"dry\", \"easy\", \"embroidery\", \"end\", \"enough\", \"even\", \"extremely\", \"fabric\", \"fall\", \"favorite\", \"feel\", \"feel\", \"feminine\", \"figure\", \"find\", \"first\", \"fit\", \"fit\", \"flare\", \"flat\", \"flattering\", \"flower\", \"flowy\", \"frame\", \"front\", \"get\", \"get\", \"girl\", \"give\", \"give\", \"glad\", \"go\", \"good\", \"gorgeous\", \"great\", \"green\", \"hang\", \"happy\", \"hard\", \"help\", \"hide\", \"hip\", \"however\", \"incredibly\", \"item\", \"keep\", \"knee\", \"knit\", \"large\", \"lay\", \"lbs\", \"leg\", \"legging\", \"length\", \"less\", \"light\", \"lightweight\", \"like\", \"line\", \"little\", \"long\", \"look\", \"loose\", \"love\", \"low\", \"make\", \"many\", \"material\", \"may\", \"medium\", \"model\", \"much\", \"need\", \"need\", \"nice\", \"nice\", \"note\", \"old\", \"one\", \"online\", \"open\", \"order\", \"other\", \"pair\", \"part\", \"pattern\", \"perfect\", \"perfectly\", \"person\", \"petite\", \"picture\", \"piece\", \"pink\", \"pocket\", \"pretty\", \"pretty\", \"price\", \"print\", \"problem\", \"purchase\", \"put\", \"quality\", \"rather\", \"read\", \"really\", \"receive\", \"recommend\", \"red\", \"regular\", \"retailer\", \"return\", \"review\", \"reviewer\", \"right\", \"rise\", \"romper\", \"run\", \"sale\", \"sandal\", \"say\", \"say\", \"season\", \"see\", \"see\", \"see\", \"seem\", \"shape\", \"shape\", \"sheer\", \"shirt\", \"shirt\", \"short\", \"short\", \"shoulder\", \"show\", \"side\", \"size\", \"sizing\", \"skin\", \"sleeve\", \"slightly\", \"slim\", \"slit\", \"small\", \"soft\", \"sort\", \"stiff\", \"still\", \"store\", \"straight\", \"strap\", \"style\", \"subtle\", \"suit\", \"summer\", \"super\", \"tall\", \"tank\", \"tee\", \"tell\", \"thick\", \"thin\", \"thing\", \"think\", \"think\", \"thought\", \"tie\", \"tight\", \"time\", \"torso\", \"touch\", \"true\", \"try\", \"type\", \"unfortunately\", \"unique\", \"usually\", \"waist\", \"walk\", \"want\", \"want\", \"wash\", \"way\", \"wear\", \"well\", \"well\", \"white\", \"wide\", \"wish\", \"wish\", \"woman\", \"work\", \"worry\", \"would\", \"would\", \"year\", \"zip\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 2, 6, 1, 3, 5, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el950253451928645754841709\", ldavis_el950253451928645754841709_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el950253451928645754841709\", ldavis_el950253451928645754841709_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el950253451928645754841709\", ldavis_el950253451928645754841709_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "6     -0.234047  0.233751       1        1  26.955095\n",
       "1     -0.176957 -0.368228       2        1  25.234377\n",
       "5     -0.227549  0.047778       3        1  21.823820\n",
       "0      0.180825 -0.051275       4        1   8.887337\n",
       "2      0.094491  0.174917       5        1   8.583557\n",
       "4      0.192657 -0.024226       6        1   5.552508\n",
       "3      0.170580 -0.012716       7        1   2.963308, topic_info=        Term          Freq         Total Category  logprob  loglift\n",
       "70     color   6886.000000   6886.000000  Default  30.0000  30.0000\n",
       "98      look   9236.000000   9236.000000  Default  29.0000  29.0000\n",
       "56      wear   9932.000000   9932.000000  Default  28.0000  28.0000\n",
       "44      size  10315.000000  10315.000000  Default  27.0000  27.0000\n",
       "12      love   9234.000000   9234.000000  Default  26.0000  26.0000\n",
       "...      ...           ...           ...      ...      ...      ...\n",
       "1482    draw    163.370636    164.226685   Topic7  -4.5597   3.5136\n",
       "169      old    158.767059    159.621338   Topic7  -4.5883   3.5135\n",
       "801    stiff    153.354584    154.208496   Topic7  -4.6230   3.5133\n",
       "521     sort    143.318558    144.172836   Topic7  -4.6907   3.5129\n",
       "488   barely    141.730072    142.583740   Topic7  -4.7018   3.5129\n",
       "\n",
       "[262 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "0         5  0.999269  absolutely\n",
       "469       3  0.998696    actually\n",
       "57        6  0.997542  adjustable\n",
       "455       5  0.998120    adorable\n",
       "943       6  0.998724       agree\n",
       "...     ...       ...         ...\n",
       "1157      7  0.994492       worry\n",
       "22        1  0.089994       would\n",
       "22        3  0.909861       would\n",
       "160       4  0.997093        year\n",
       "51        6  0.997674         zip\n",
       "\n",
       "[252 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 2, 6, 1, 3, 5, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LDA mallet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = './data/mallet-2.0.8/bin/mallet' \n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=5, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('size', 0.112959128813443),\n",
      "   ('small', 0.06162134956131822),\n",
      "   ('fit', 0.059745370105581036),\n",
      "   ('order', 0.05412887063748985),\n",
      "   ('large', 0.039018084899509274),\n",
      "   ('run', 0.03477425332585992),\n",
      "   ('waist', 0.02590910650758971),\n",
      "   ('medium', 0.024650827604351357),\n",
      "   ('big', 0.024078882648333924),\n",
      "   ('tight', 0.020086706855332242)]),\n",
      " (1,\n",
      "  [('wear', 0.07955520594965675),\n",
      "   ('perfect', 0.0442052822273074),\n",
      "   ('great', 0.042250667429443174),\n",
      "   ('long', 0.0377336003051106),\n",
      "   ('fit', 0.036684782608695655),\n",
      "   ('work', 0.033979309687261636),\n",
      "   ('length', 0.03176249046529367),\n",
      "   ('short', 0.02720966819221968),\n",
      "   ('petite', 0.026101258581235697),\n",
      "   ('love', 0.023979786422578184)]),\n",
      " (2,\n",
      "  [('soft', 0.04066055398204599),\n",
      "   ('love', 0.03434784695885939),\n",
      "   ('fabric', 0.033987806634343046),\n",
      "   ('nice', 0.0319955835053526),\n",
      "   ('great', 0.02955931064279199),\n",
      "   ('material', 0.02851519370169459),\n",
      "   ('feel', 0.02552685900820892),\n",
      "   ('comfortable', 0.02298257404829341),\n",
      "   ('fall', 0.022010465172099276),\n",
      "   ('make', 0.017521962459795495)]),\n",
      " (3,\n",
      "  [('color', 0.08460405112418097),\n",
      "   ('flattering', 0.035540169854940525),\n",
      "   ('beautiful', 0.035420384988560545),\n",
      "   ('make', 0.033372063773462864),\n",
      "   ('back', 0.03197058083681708),\n",
      "   ('shirt', 0.031000323419139227),\n",
      "   ('pretty', 0.02739479894110178),\n",
      "   ('cut', 0.022974737371680463),\n",
      "   ('fabric', 0.01999209419881892),\n",
      "   ('picture', 0.019369212893643017)]),\n",
      " (4,\n",
      "  [('buy', 0.047289888925966535),\n",
      "   ('wear', 0.03561043047146875),\n",
      "   ('love', 0.03286933307908662),\n",
      "   ('purchase', 0.02692234351909234),\n",
      "   ('retailer', 0.025408781045907422),\n",
      "   ('store', 0.02434809553320303),\n",
      "   ('quality', 0.023132478428755304),\n",
      "   ('cute', 0.01653000905753921),\n",
      "   ('online', 0.016506173428040234),\n",
      "   ('sale', 0.016220145874052534)])]\n",
      "\n",
      "Coherence Score:  0.45523653209280185\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v', topn=10)\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check coherence score amongs various topic numbers:\n",
    "    \n",
    "def lda_malle(number_topics):\n",
    "    coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v', topn=number_topics)\n",
    "    coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "    return coherence_ldamallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,21):\n",
    "#    print(f'{i} topics: coherence score {lda_malle(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    \n",
    "  \n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=10, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=10; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3493\n",
      "Num Topics = 3  has Coherence Value of 0.3932\n",
      "Num Topics = 4  has Coherence Value of 0.3985\n",
      "Num Topics = 5  has Coherence Value of 0.4098\n",
      "Num Topics = 6  has Coherence Value of 0.4328\n",
      "Num Topics = 7  has Coherence Value of 0.4264\n",
      "Num Topics = 8  has Coherence Value of 0.4328\n",
      "Num Topics = 9  has Coherence Value of 0.4382\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.093*\"wear\" + 0.092*\"great\" + 0.060*\"perfect\" + 0.048*\"comfortable\" + '\n",
      "  '0.030*\"fall\" + 0.026*\"love\" + 0.026*\"summer\" + 0.021*\"pair\" + 0.020*\"piece\" '\n",
      "  '+ 0.019*\"soft\"'),\n",
      " (1,\n",
      "  '0.074*\"fabric\" + 0.059*\"make\" + 0.049*\"feel\" + 0.046*\"nice\" + '\n",
      "  '0.045*\"material\" + 0.036*\"quality\" + 0.027*\"design\" + 0.025*\"good\" + '\n",
      "  '0.022*\"high\" + 0.021*\"give\"'),\n",
      " (2,\n",
      "  '0.052*\"long\" + 0.045*\"back\" + 0.038*\"short\" + 0.031*\"sleeve\" + '\n",
      "  '0.024*\"length\" + 0.023*\"model\" + 0.021*\"front\" + 0.021*\"side\" + '\n",
      "  '0.021*\"picture\" + 0.021*\"show\"'),\n",
      " (3,\n",
      "  '0.119*\"color\" + 0.097*\"love\" + 0.046*\"beautiful\" + 0.044*\"buy\" + '\n",
      "  '0.035*\"purchase\" + 0.027*\"black\" + 0.026*\"flattering\" + 0.016*\"white\" + '\n",
      "  '0.016*\"detail\" + 0.015*\"soft\"'),\n",
      " (4,\n",
      "  '0.088*\"small\" + 0.055*\"large\" + 0.049*\"run\" + 0.036*\"fit\" + 0.035*\"medium\" '\n",
      "  '+ 0.034*\"big\" + 0.032*\"waist\" + 0.029*\"tight\" + 0.022*\"bit\" + '\n",
      "  '0.022*\"bottom\"'),\n",
      " (5,\n",
      "  '0.149*\"size\" + 0.102*\"fit\" + 0.077*\"order\" + 0.036*\"petite\" + 0.034*\"store\" '\n",
      "  '+ 0.028*\"true\" + 0.025*\"find\" + 0.024*\"perfectly\" + 0.023*\"online\" + '\n",
      "  '0.021*\"retailer\"'),\n",
      " (6,\n",
      "  '0.071*\"wear\" + 0.050*\"cute\" + 0.044*\"shirt\" + 0.032*\"style\" + 0.031*\"love\" '\n",
      "  '+ 0.023*\"buy\" + 0.023*\"sale\" + 0.023*\"price\" + 0.021*\"pretty\" + '\n",
      "  '0.018*\"super\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[5] # canviar pel que vulgui\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>color, love, beautiful, buy, purchase, black, ...</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>wear, great, perfect, comfortable, fall, love,...</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>wear, great, perfect, comfortable, fall, love,...</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>wear, cute, shirt, style, love, buy, sale, pri...</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>color, love, beautiful, buy, purchase, black, ...</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>I love this dress. i usually get an xs but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>I'm 5\"5' and 125 lbs. i ordered the s petite t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             3.0              0.1693   \n",
       "1            1             5.0              0.2648   \n",
       "2            2             5.0              0.2370   \n",
       "3            3             0.0              0.1673   \n",
       "4            4             0.0              0.2019   \n",
       "5            5             6.0              0.1759   \n",
       "6            6             5.0              0.2129   \n",
       "7            7             3.0              0.1818   \n",
       "8            8             5.0              0.1754   \n",
       "9            9             5.0              0.1779   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  color, love, beautiful, buy, purchase, black, ...   \n",
       "1  size, fit, order, petite, store, true, find, p...   \n",
       "2  size, fit, order, petite, store, true, find, p...   \n",
       "3  wear, great, perfect, comfortable, fall, love,...   \n",
       "4  wear, great, perfect, comfortable, fall, love,...   \n",
       "5  wear, cute, shirt, style, love, buy, sale, pri...   \n",
       "6  size, fit, order, petite, store, true, find, p...   \n",
       "7  color, love, beautiful, buy, purchase, black, ...   \n",
       "8  size, fit, order, petite, store, true, find, p...   \n",
       "9  size, fit, order, petite, store, true, find, p...   \n",
       "\n",
       "                                                Text  \n",
       "0  Absolutely wonderful - silky and sexy and comf...  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...  \n",
       "2  I had such high hopes for this dress and reall...  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...  \n",
       "4  This shirt is very flattering to all due to th...  \n",
       "5  I love tracy reese dresses, but this one is no...  \n",
       "6  I aded this in my basket at hte last mintue to...  \n",
       "7  I ordered this in carbon for store pick up, an...  \n",
       "8  I love this dress. i usually get an xs but it ...  \n",
       "9  I'm 5\"5' and 125 lbs. i ordered the s petite t...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df['review_text']):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=df['review_text'])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>color, love, beautiful, buy, purchase, black, ...</td>\n",
       "      <td>4163.0</td>\n",
       "      <td>0.1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>0.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>size, fit, order, petite, store, true, find, p...</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>wear, great, perfect, comfortable, fall, love,...</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>0.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>wear, great, perfect, comfortable, fall, love,...</td>\n",
       "      <td>3539.0</td>\n",
       "      <td>0.1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23458 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dominant_Topic                                     Topic_Keywords  \\\n",
       "0.0                 3.0  color, love, beautiful, buy, purchase, black, ...   \n",
       "1.0                 5.0  size, fit, order, petite, store, true, find, p...   \n",
       "2.0                 5.0  size, fit, order, petite, store, true, find, p...   \n",
       "3.0                 0.0  wear, great, perfect, comfortable, fall, love,...   \n",
       "4.0                 0.0  wear, great, perfect, comfortable, fall, love,...   \n",
       "...                 ...                                                ...   \n",
       "23481.0             NaN                                                NaN   \n",
       "23482.0             NaN                                                NaN   \n",
       "23483.0             NaN                                                NaN   \n",
       "23484.0             NaN                                                NaN   \n",
       "23485.0             NaN                                                NaN   \n",
       "\n",
       "         Num_Documents  Perc_Documents  \n",
       "0.0             4163.0          0.1840  \n",
       "1.0             3032.0          0.1340  \n",
       "2.0             3052.0          0.1349  \n",
       "3.0             3150.0          0.1392  \n",
       "4.0             3539.0          0.1564  \n",
       "...                ...             ...  \n",
       "23481.0            NaN             NaN  \n",
       "23482.0            NaN             NaN  \n",
       "23483.0            NaN             NaN  \n",
       "23484.0            NaN             NaN  \n",
       "23485.0            NaN             NaN  \n",
       "\n",
       "[23458 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4163\n",
       "4.0    3539\n",
       "3.0    3150\n",
       "5.0    3105\n",
       "2.0    3052\n",
       "1.0    3032\n",
       "6.0    2587\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.Dominant_Topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_dominant_topic.loc[df_dominant_topic.Dominant_Topic==0]['Text'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.2/libexec/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stars'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-aedb89521d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dominant_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.2/libexec/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.2/libexec/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stars'"
     ]
    }
   ],
   "source": [
    "df_final = pd.merge(df_dominant_topic, df['stars'], how='inner', left_index=True, right_index=True)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.groupby('Dominant_Topic').stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_final.loc[(df_final.Dominant_Topic==0)&(df_final.stars==1)]['Text'])[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
